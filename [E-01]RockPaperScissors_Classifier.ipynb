{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploaration Project 01. Rock Paper Scissors Classifier\n",
    "\n",
    "## 00. get dataset\n",
    "- 구글의 [teachable machine 사이트](https://teachablemachine.withgoogle.com/)를 이용해서 가위바위보 사진을 촬영한다.\n",
    "- 촬영한 이미지의 크기를 224x224 => 28x28로 변경한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "# PIL 라이브러리가 설치되어 있지 않다면 설치\n",
    "# !pip install pillow   \n",
    "\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "import numpy as np\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/project/Project_AIFFEL/dataset/rock_scissors_paper/rock\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/project/Project_AIFFEL/dataset/rock_scissors_paper/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/project/Project_AIFFEL/dataset/rock_scissors_paper/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/project/Project_AIFFEL/dataset/rock_scissors_paper/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/project/Project_AIFFEL/dataset/rock_scissors_paper/scissors\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/project/Project_AIFFEL/dataset/rock_scissors_paper/scissors\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. load data\n",
    "- load_data 함수를 만들어 데이터를 불러온다.\n",
    "- 이미지와 정답 데이터를 담을 행렬을 미리 만든다.\n",
    "- 이미지가 담겨있는 폴더에서 이미지를 불러와 행렬에 저장한다.(for loop사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 3000 입니다.\n",
      "x_train shape: (2400, 28, 28, 3)\n",
      "y_train shape: (2400,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=3000   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissors/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/project/Project_AIFFEL/dataset/rock_scissors_paper/\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = model_selection.train_test_split(x_train_norm, y_train, test_size=0.2)\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이미지 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. build Deep Learning network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 3 from 1 for '{{node conv2d_3/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](max_pooling2d_2/Identity, conv2d_3/Conv2D/ReadVariableOp)' with input shapes: [?,1,1,64], [3,3,64,128].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1653\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1654\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1655\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 3 from 1 for '{{node conv2d_3/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](max_pooling2d_2/Identity, conv2d_3/Conv2D/ReadVariableOp)' with input shapes: [?,1,1,64], [3,3,64,128].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f5905b63702e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    211\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    920\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[1;32m    921\u001b[0m                   \u001b[0;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    923\u001b[0m                     \u001b[0;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0;31m# circular dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    205\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m   1104\u001b[0m           call_from_convolution=False)\n\u001b[1;32m   1105\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         name=self.name)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)\u001b[0m\n\u001b[1;32m   2012\u001b[0m                            \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m                            \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2014\u001b[0;31m                            name=name)\n\u001b[0m\u001b[1;32m   2015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    967\u001b[0m                   \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m                   \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m                   data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[1;32m    970\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    742\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    743\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    593\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    594\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3325\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3326\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3327\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3328\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1815\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0;32m-> 1817\u001b[0;31m                                 control_input_ops, op_def)\n\u001b[0m\u001b[1;32m   1818\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1655\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 3 from 1 for '{{node conv2d_3/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](max_pooling2d_2/Identity, conv2d_3/Conv2D/ReadVariableOp)' with input shapes: [?,1,1,64], [3,3,64,128]."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**trouble**\n",
    "- 레이어를 많이 쌓으려고 했는데, Convolution 연산을 여러번 하기에 28x28 사이즈의 이미지는 많이 작았다. \n",
    "- 3번 연산을 한 후의 output shape이 (None, 1, 1, 64)로 더이상 연산을 할 수 없어서 Error발생\n",
    "- 28x28 사이즈의 이미지에서는 (3,3) convolution연산이 최대 3번만 가능하다.   \n",
    "\n",
    "**output shape 계산 방법**\n",
    "- keras의 Conv2D의 default stride = 1\n",
    "- (n x n)의 convolution layer라고 가정\n",
    "- (m x m x colour channel)의 input shape라고 가정 \n",
    "- output shape = (m - n + 1) x (m - n + 1)\n",
    "- **만약** stride = 3 이라면, output shape = (m - n + 1)/3 x (m - n + 1)/3     \n",
    "\n",
    "**네트워크 설계하기**\n",
    "- 계산 가능한 수의 레이어를 쌓았다.\n",
    "- 최종 dense layer는 가위, 바위, 보 3개의 class이므로 3을 넣는다.\n",
    "- activation : 최종 dense layer에는 softmax를 사용해 multi classification이 가능하게 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 113,987\n",
      "Trainable params: 113,987\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. train data with your network\n",
    "- model.compile(), model.fit()을 이용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "75/75 [==============================] - 3s 40ms/step - loss: 1.0913 - accuracy: 0.3617 - val_loss: 1.0657 - val_accuracy: 0.4567\n",
      "Epoch 2/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.9665 - accuracy: 0.5050 - val_loss: 0.8684 - val_accuracy: 0.5650\n",
      "Epoch 3/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.6875 - val_loss: 0.6685 - val_accuracy: 0.7450\n",
      "Epoch 4/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7967 - val_loss: 0.5048 - val_accuracy: 0.8233\n",
      "Epoch 5/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3478 - accuracy: 0.8683 - val_loss: 0.3965 - val_accuracy: 0.8183\n",
      "Epoch 6/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.2954 - accuracy: 0.8846 - val_loss: 0.2903 - val_accuracy: 0.9000\n",
      "Epoch 7/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1836 - accuracy: 0.9438 - val_loss: 0.3018 - val_accuracy: 0.8983\n",
      "Epoch 8/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.1739 - accuracy: 0.9442 - val_loss: 0.2134 - val_accuracy: 0.9300\n",
      "Epoch 9/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0926 - accuracy: 0.9721 - val_loss: 0.1808 - val_accuracy: 0.9550\n",
      "Epoch 10/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.9808 - val_loss: 0.1344 - val_accuracy: 0.9650\n",
      "Epoch 11/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 0.9871 - val_loss: 0.1558 - val_accuracy: 0.9550\n",
      "Epoch 12/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9912 - val_loss: 0.1160 - val_accuracy: 0.9667\n",
      "Epoch 13/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9958 - val_loss: 0.1032 - val_accuracy: 0.9767\n",
      "Epoch 14/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.9962 - val_loss: 0.1343 - val_accuracy: 0.9667\n",
      "Epoch 15/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.9779 - val_loss: 0.2723 - val_accuracy: 0.8850\n",
      "Epoch 16/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0513 - accuracy: 0.9842 - val_loss: 0.2285 - val_accuracy: 0.9217\n",
      "Epoch 17/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9842 - val_loss: 0.1604 - val_accuracy: 0.9483\n",
      "Epoch 18/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 0.9912 - val_loss: 0.1191 - val_accuracy: 0.9733\n",
      "Epoch 19/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.2616 - val_accuracy: 0.9533\n",
      "Epoch 20/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 0.9983 - val_loss: 0.1070 - val_accuracy: 0.9767\n",
      "Epoch 21/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1239 - val_accuracy: 0.9717\n",
      "Epoch 22/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.1117 - val_accuracy: 0.9800\n",
      "Epoch 23/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1092 - val_accuracy: 0.9817\n",
      "Epoch 24/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 6.2902e-04 - accuracy: 1.0000 - val_loss: 0.1101 - val_accuracy: 0.9783\n",
      "Epoch 25/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 5.0388e-04 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 0.9817\n",
      "Epoch 26/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 4.3382e-04 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9817\n",
      "Epoch 27/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 3.8247e-04 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9817\n",
      "Epoch 28/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 3.3470e-04 - accuracy: 1.0000 - val_loss: 0.1116 - val_accuracy: 0.9800\n",
      "Epoch 29/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 3.0562e-04 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9817\n",
      "Epoch 30/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.6925e-04 - accuracy: 1.0000 - val_loss: 0.1111 - val_accuracy: 0.9817\n",
      "Epoch 31/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.4942e-04 - accuracy: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9817\n",
      "Epoch 32/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.2654e-04 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 0.9817\n",
      "Epoch 33/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.1003e-04 - accuracy: 1.0000 - val_loss: 0.1155 - val_accuracy: 0.9817\n",
      "Epoch 34/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.8824e-04 - accuracy: 1.0000 - val_loss: 0.1149 - val_accuracy: 0.9800\n",
      "Epoch 35/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.8249e-04 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 0.9817\n",
      "Epoch 36/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.6339e-04 - accuracy: 1.0000 - val_loss: 0.1160 - val_accuracy: 0.9817\n",
      "Epoch 37/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.5628e-04 - accuracy: 1.0000 - val_loss: 0.1171 - val_accuracy: 0.9817\n",
      "Epoch 38/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4588e-04 - accuracy: 1.0000 - val_loss: 0.1191 - val_accuracy: 0.9817\n",
      "Epoch 39/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.3588e-04 - accuracy: 1.0000 - val_loss: 0.1184 - val_accuracy: 0.9817\n",
      "Epoch 40/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.2477e-04 - accuracy: 1.0000 - val_loss: 0.1188 - val_accuracy: 0.9817\n",
      "Epoch 41/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.1702e-04 - accuracy: 1.0000 - val_loss: 0.1209 - val_accuracy: 0.9817\n",
      "Epoch 42/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.0866e-04 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9817\n",
      "Epoch 43/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.0395e-04 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9817\n",
      "Epoch 44/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 9.4671e-05 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 0.9817\n",
      "Epoch 45/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 9.3887e-05 - accuracy: 1.0000 - val_loss: 0.1228 - val_accuracy: 0.9817\n",
      "Epoch 46/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 8.6310e-05 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9817\n",
      "Epoch 47/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 8.1502e-05 - accuracy: 1.0000 - val_loss: 0.1246 - val_accuracy: 0.9817\n",
      "Epoch 48/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 7.6653e-05 - accuracy: 1.0000 - val_loss: 0.1253 - val_accuracy: 0.9817\n",
      "Epoch 49/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 7.0887e-05 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9817\n",
      "Epoch 50/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 6.9439e-05 - accuracy: 1.0000 - val_loss: 0.1262 - val_accuracy: 0.9817\n",
      "Epoch 51/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 6.4828e-05 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9817\n",
      "Epoch 52/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 6.1445e-05 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 0.9817\n",
      "Epoch 53/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 5.7742e-05 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 0.9817\n",
      "Epoch 54/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 5.5216e-05 - accuracy: 1.0000 - val_loss: 0.1284 - val_accuracy: 0.9817\n",
      "Epoch 55/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 5.0927e-05 - accuracy: 1.0000 - val_loss: 0.1284 - val_accuracy: 0.9817\n",
      "Epoch 56/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 4.9213e-05 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 0.9817\n",
      "Epoch 57/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 4.6159e-05 - accuracy: 1.0000 - val_loss: 0.1292 - val_accuracy: 0.9817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 4.3277e-05 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.9817\n",
      "Epoch 59/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 4.1403e-05 - accuracy: 1.0000 - val_loss: 0.1307 - val_accuracy: 0.9817\n",
      "Epoch 60/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 3.9564e-05 - accuracy: 1.0000 - val_loss: 0.1314 - val_accuracy: 0.9817\n",
      "Epoch 61/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 3.7198e-05 - accuracy: 1.0000 - val_loss: 0.1319 - val_accuracy: 0.9817\n",
      "Epoch 62/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 3.5343e-05 - accuracy: 1.0000 - val_loss: 0.1325 - val_accuracy: 0.9817\n",
      "Epoch 63/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 3.4111e-05 - accuracy: 1.0000 - val_loss: 0.1348 - val_accuracy: 0.9817\n",
      "Epoch 64/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 3.2204e-05 - accuracy: 1.0000 - val_loss: 0.1340 - val_accuracy: 0.9817\n",
      "Epoch 65/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 3.0546e-05 - accuracy: 1.0000 - val_loss: 0.1345 - val_accuracy: 0.9817\n",
      "Epoch 66/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.8158e-05 - accuracy: 1.0000 - val_loss: 0.1347 - val_accuracy: 0.9817\n",
      "Epoch 67/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.7493e-05 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.9817\n",
      "Epoch 68/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.5967e-05 - accuracy: 1.0000 - val_loss: 0.1361 - val_accuracy: 0.9817\n",
      "Epoch 69/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.4367e-05 - accuracy: 1.0000 - val_loss: 0.1364 - val_accuracy: 0.9817\n",
      "Epoch 70/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.3536e-05 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.9817\n",
      "Epoch 71/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.2295e-05 - accuracy: 1.0000 - val_loss: 0.1380 - val_accuracy: 0.9817\n",
      "Epoch 72/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.1420e-05 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9817\n",
      "Epoch 73/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.0401e-05 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9817\n",
      "Epoch 74/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.9419e-05 - accuracy: 1.0000 - val_loss: 0.1386 - val_accuracy: 0.9817\n",
      "Epoch 75/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.8384e-05 - accuracy: 1.0000 - val_loss: 0.1393 - val_accuracy: 0.9817\n",
      "Epoch 76/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.8001e-05 - accuracy: 1.0000 - val_loss: 0.1398 - val_accuracy: 0.9817\n",
      "Epoch 77/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.7004e-05 - accuracy: 1.0000 - val_loss: 0.1405 - val_accuracy: 0.9817\n",
      "Epoch 78/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.6145e-05 - accuracy: 1.0000 - val_loss: 0.1416 - val_accuracy: 0.9817\n",
      "Epoch 79/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.5434e-05 - accuracy: 1.0000 - val_loss: 0.1416 - val_accuracy: 0.9817\n",
      "Epoch 80/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4612e-05 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9817\n",
      "Epoch 81/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.3889e-05 - accuracy: 1.0000 - val_loss: 0.1425 - val_accuracy: 0.9817\n",
      "Epoch 82/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.3384e-05 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9817\n",
      "Epoch 83/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.2721e-05 - accuracy: 1.0000 - val_loss: 0.1435 - val_accuracy: 0.9817\n",
      "Epoch 84/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.1819e-05 - accuracy: 1.0000 - val_loss: 0.1437 - val_accuracy: 0.9817\n",
      "Epoch 85/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.1541e-05 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9817\n",
      "Epoch 86/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.0874e-05 - accuracy: 1.0000 - val_loss: 0.1448 - val_accuracy: 0.9817\n",
      "Epoch 87/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.0507e-05 - accuracy: 1.0000 - val_loss: 0.1445 - val_accuracy: 0.9817\n",
      "Epoch 88/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.0636e-05 - accuracy: 1.0000 - val_loss: 0.1451 - val_accuracy: 0.9817\n",
      "Epoch 89/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 9.4798e-06 - accuracy: 1.0000 - val_loss: 0.1468 - val_accuracy: 0.9817\n",
      "Epoch 90/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 9.0517e-06 - accuracy: 1.0000 - val_loss: 0.1468 - val_accuracy: 0.9817\n",
      "Epoch 91/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 8.5803e-06 - accuracy: 1.0000 - val_loss: 0.1476 - val_accuracy: 0.9817\n",
      "Epoch 92/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 8.3323e-06 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 0.9817\n",
      "Epoch 93/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 8.0209e-06 - accuracy: 1.0000 - val_loss: 0.1476 - val_accuracy: 0.9817\n",
      "Epoch 94/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 7.5862e-06 - accuracy: 1.0000 - val_loss: 0.1485 - val_accuracy: 0.9817\n",
      "Epoch 95/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 7.2635e-06 - accuracy: 1.0000 - val_loss: 0.1480 - val_accuracy: 0.9817\n",
      "Epoch 96/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 7.0256e-06 - accuracy: 1.0000 - val_loss: 0.1486 - val_accuracy: 0.9817\n",
      "Epoch 97/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 6.6458e-06 - accuracy: 1.0000 - val_loss: 0.1497 - val_accuracy: 0.9817\n",
      "Epoch 98/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 6.3982e-06 - accuracy: 1.0000 - val_loss: 0.1500 - val_accuracy: 0.9817\n",
      "Epoch 99/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 6.1242e-06 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 0.9817\n",
      "Epoch 100/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 5.7851e-06 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 0.9817\n",
      "Epoch 101/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 5.5580e-06 - accuracy: 1.0000 - val_loss: 0.1509 - val_accuracy: 0.9817\n",
      "Epoch 102/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 5.3164e-06 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9817\n",
      "Epoch 103/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 5.0951e-06 - accuracy: 1.0000 - val_loss: 0.1515 - val_accuracy: 0.9817\n",
      "Epoch 104/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 4.7947e-06 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9817\n",
      "Epoch 105/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 4.5959e-06 - accuracy: 1.0000 - val_loss: 0.1523 - val_accuracy: 0.9817\n",
      "Epoch 106/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 4.4182e-06 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9817\n",
      "Epoch 107/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 4.2831e-06 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9817\n",
      "Epoch 108/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 4.0492e-06 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9817\n",
      "Epoch 109/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 3.8549e-06 - accuracy: 1.0000 - val_loss: 0.1541 - val_accuracy: 0.9817\n",
      "Epoch 110/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 3.7462e-06 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9817\n",
      "Epoch 111/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 3.5685e-06 - accuracy: 1.0000 - val_loss: 0.1552 - val_accuracy: 0.9817\n",
      "Epoch 112/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 3.3875e-06 - accuracy: 1.0000 - val_loss: 0.1555 - val_accuracy: 0.9817\n",
      "Epoch 113/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 3.2877e-06 - accuracy: 1.0000 - val_loss: 0.1555 - val_accuracy: 0.9817\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 2ms/step - loss: 3.1059e-06 - accuracy: 1.0000 - val_loss: 0.1562 - val_accuracy: 0.9817\n",
      "Epoch 115/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.9946e-06 - accuracy: 1.0000 - val_loss: 0.1561 - val_accuracy: 0.9817\n",
      "Epoch 116/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.8362e-06 - accuracy: 1.0000 - val_loss: 0.1574 - val_accuracy: 0.9817\n",
      "Epoch 117/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.6642e-06 - accuracy: 1.0000 - val_loss: 0.1582 - val_accuracy: 0.9817\n",
      "Epoch 118/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.6531e-06 - accuracy: 1.0000 - val_loss: 0.1580 - val_accuracy: 0.9817\n",
      "Epoch 119/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.4849e-06 - accuracy: 1.0000 - val_loss: 0.1586 - val_accuracy: 0.9817\n",
      "Epoch 120/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.3474e-06 - accuracy: 1.0000 - val_loss: 0.1588 - val_accuracy: 0.9817\n",
      "Epoch 121/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.2540e-06 - accuracy: 1.0000 - val_loss: 0.1591 - val_accuracy: 0.9817\n",
      "Epoch 122/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.1771e-06 - accuracy: 1.0000 - val_loss: 0.1597 - val_accuracy: 0.9817\n",
      "Epoch 123/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.0490e-06 - accuracy: 1.0000 - val_loss: 0.1607 - val_accuracy: 0.9817\n",
      "Epoch 124/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.9379e-06 - accuracy: 1.0000 - val_loss: 0.1611 - val_accuracy: 0.9817\n",
      "Epoch 125/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.9048e-06 - accuracy: 1.0000 - val_loss: 0.1606 - val_accuracy: 0.9817\n",
      "Epoch 126/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.8139e-06 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 0.9817\n",
      "Epoch 127/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.7699e-06 - accuracy: 1.0000 - val_loss: 0.1618 - val_accuracy: 0.9817\n",
      "Epoch 128/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.6705e-06 - accuracy: 1.0000 - val_loss: 0.1622 - val_accuracy: 0.9817\n",
      "Epoch 129/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.5963e-06 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 0.9817\n",
      "Epoch 130/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.5719e-06 - accuracy: 1.0000 - val_loss: 0.1625 - val_accuracy: 0.9817\n",
      "Epoch 131/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4662e-06 - accuracy: 1.0000 - val_loss: 0.1630 - val_accuracy: 0.9817\n",
      "Epoch 132/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.3682e-06 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.9817\n",
      "Epoch 133/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.3199e-06 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.9817\n",
      "Epoch 134/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.2541e-06 - accuracy: 1.0000 - val_loss: 0.1641 - val_accuracy: 0.9817\n",
      "Epoch 135/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.2011e-06 - accuracy: 1.0000 - val_loss: 0.1650 - val_accuracy: 0.9817\n",
      "Epoch 136/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.1415e-06 - accuracy: 1.0000 - val_loss: 0.1657 - val_accuracy: 0.9817\n",
      "Epoch 137/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.1002e-06 - accuracy: 1.0000 - val_loss: 0.1666 - val_accuracy: 0.9817\n",
      "Epoch 138/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.0418e-06 - accuracy: 1.0000 - val_loss: 0.1657 - val_accuracy: 0.9833\n",
      "Epoch 139/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.0113e-06 - accuracy: 1.0000 - val_loss: 0.1667 - val_accuracy: 0.9817\n",
      "Epoch 140/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 9.6216e-07 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9817\n",
      "Epoch 141/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 9.1602e-07 - accuracy: 1.0000 - val_loss: 0.1672 - val_accuracy: 0.9817\n",
      "Epoch 142/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 8.8835e-07 - accuracy: 1.0000 - val_loss: 0.1685 - val_accuracy: 0.9817\n",
      "Epoch 143/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 8.2572e-07 - accuracy: 1.0000 - val_loss: 0.1676 - val_accuracy: 0.9833\n",
      "Epoch 144/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 8.0634e-07 - accuracy: 1.0000 - val_loss: 0.1684 - val_accuracy: 0.9833\n",
      "Epoch 145/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 7.6909e-07 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.9833\n",
      "Epoch 146/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 7.2975e-07 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 0.9817\n",
      "Epoch 147/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 7.0318e-07 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 0.9833\n",
      "Epoch 148/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 6.4919e-07 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 0.9833\n",
      "Epoch 149/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 6.1671e-07 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 0.9833\n",
      "Epoch 150/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 5.7742e-07 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 0.9817\n",
      "Epoch 151/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 5.4459e-07 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 0.9833\n",
      "Epoch 152/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 5.2650e-07 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 0.9833\n",
      "Epoch 153/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 4.8950e-07 - accuracy: 1.0000 - val_loss: 0.1727 - val_accuracy: 0.9833\n",
      "Epoch 154/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 4.6283e-07 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 0.9817\n",
      "Epoch 155/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 4.3919e-07 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.9833\n",
      "Epoch 156/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 4.1529e-07 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9817\n",
      "Epoch 157/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 4.0471e-07 - accuracy: 1.0000 - val_loss: 0.1748 - val_accuracy: 0.9817\n",
      "Epoch 158/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 3.7432e-07 - accuracy: 1.0000 - val_loss: 0.1747 - val_accuracy: 0.9833\n",
      "Epoch 159/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 3.5231e-07 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 0.9833\n",
      "Epoch 160/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 3.3607e-07 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 0.9817\n",
      "Epoch 161/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 3.1859e-07 - accuracy: 1.0000 - val_loss: 0.1767 - val_accuracy: 0.9817\n",
      "Epoch 162/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 3.0478e-07 - accuracy: 1.0000 - val_loss: 0.1776 - val_accuracy: 0.9817\n",
      "Epoch 163/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.9166e-07 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9817\n",
      "Epoch 164/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.7507e-07 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9833\n",
      "Epoch 165/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.5680e-07 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 0.9817\n",
      "Epoch 166/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.4741e-07 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 0.9817\n",
      "Epoch 167/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.3390e-07 - accuracy: 1.0000 - val_loss: 0.1776 - val_accuracy: 0.9833\n",
      "Epoch 168/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.2451e-07 - accuracy: 1.0000 - val_loss: 0.1788 - val_accuracy: 0.9833\n",
      "Epoch 169/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.1065e-07 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 2.0171e-07 - accuracy: 1.0000 - val_loss: 0.1797 - val_accuracy: 0.9833\n",
      "Epoch 171/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.9376e-07 - accuracy: 1.0000 - val_loss: 0.1801 - val_accuracy: 0.9817\n",
      "Epoch 172/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.8567e-07 - accuracy: 1.0000 - val_loss: 0.1805 - val_accuracy: 0.9833\n",
      "Epoch 173/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.7638e-07 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.9833\n",
      "Epoch 174/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.6515e-07 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9817\n",
      "Epoch 175/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.5870e-07 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 0.9833\n",
      "Epoch 176/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.5154e-07 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 0.9833\n",
      "Epoch 177/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.4414e-07 - accuracy: 1.0000 - val_loss: 0.1826 - val_accuracy: 0.9833\n",
      "Epoch 178/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.3759e-07 - accuracy: 1.0000 - val_loss: 0.1831 - val_accuracy: 0.9833\n",
      "Epoch 179/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.3153e-07 - accuracy: 1.0000 - val_loss: 0.1831 - val_accuracy: 0.9833\n",
      "Epoch 180/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.2929e-07 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9817\n",
      "Epoch 181/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.2070e-07 - accuracy: 1.0000 - val_loss: 0.1839 - val_accuracy: 0.9833\n",
      "Epoch 182/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.1578e-07 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9833\n",
      "Epoch 183/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.1305e-07 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9833\n",
      "Epoch 184/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.0585e-07 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9833\n",
      "Epoch 185/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 9.9192e-08 - accuracy: 1.0000 - val_loss: 0.1853 - val_accuracy: 0.9833\n",
      "Epoch 186/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 9.5864e-08 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9833\n",
      "Epoch 187/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 9.1692e-08 - accuracy: 1.0000 - val_loss: 0.1853 - val_accuracy: 0.9833\n",
      "Epoch 188/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 8.8016e-08 - accuracy: 1.0000 - val_loss: 0.1864 - val_accuracy: 0.9833\n",
      "Epoch 189/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 8.3894e-08 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9833\n",
      "Epoch 190/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 8.0417e-08 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9833\n",
      "Epoch 191/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 7.7387e-08 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9833\n",
      "Epoch 192/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 7.4754e-08 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9833\n",
      "Epoch 193/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 7.2867e-08 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.9833\n",
      "Epoch 194/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 6.7999e-08 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9833\n",
      "Epoch 195/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 6.6012e-08 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9833\n",
      "Epoch 196/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 6.1095e-08 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9833\n",
      "Epoch 197/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 5.9456e-08 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9833\n",
      "Epoch 198/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 5.6922e-08 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9833\n",
      "Epoch 199/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 5.3793e-08 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9833\n",
      "Epoch 200/200\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 5.1359e-08 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7c605a2390>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=200, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. evaluate your network with test data\n",
    "- test data를 로드해 dataset을 train과 같이 만들어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (3000, 28, 28, 3)\n",
      "y_test shape: (3000,)\n"
     ]
    }
   ],
   "source": [
    "def load_test_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissors/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"평가데이터(x_test)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/project/Project_AIFFEL/dataset/rock_scissors_paper_test/\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- model.evaluate()로 평가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 - 0s - loss: 18.6495 - accuracy: 0.0353\n",
      "test_loss: 18.649517059326172 \n",
      "test_accuracy: 0.03533333167433739\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test_accuracy를 높이자\n",
    "1. test_accuracy: 0.31333333253860474   \n",
    "    : train data 수가 300개로 test data와 같아서 test 정확도가 train_accuracy(1.0)에 비해 현저히 낮은 것으로 추정된다. \n",
    "2. test_accuracy: 0.3333333432674408\n",
    "    : train data 300 -> 1200으로 늘렸으나 미미하게 올라감\n",
    "3. test_accuracy: 0.36666667461395264\n",
    "    : train data 1200 -> 3000으로 늘렸으나 미미하게 올라감\n",
    "    => validation split을 해보자!\n",
    "3. test_accuracy: 0.03133333474397659\n",
    "    : test_size=0.2로 split, epoch= 50 -> 200 으로 변경했으나 오히려 떨어짐  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
