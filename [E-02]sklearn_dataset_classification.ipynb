{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [E-02]sklearn dataset classification\n",
    "- task : sklearn.datasets에 있는 digits, wine, breast cancer data를 분류한다.\n",
    "- 5가지 machine learning 알고리즘으로 분류한다. \n",
    "    - Decision Tree, Random Forest, SVM, SGD Classifier, Logistic Regression\n",
    "- confusion matrix를 이해하고, dataset에 따라 적합한 평가지표를 선정해 평가한다.\n",
    "\n",
    "---\n",
    "\n",
    "# project(1). digits classification\n",
    "## 01. load dataset \n",
    "- sklearn.datasets 모듈을 import해서 dataset을 가져온다.\n",
    "- digits dataset : 0~9까지 10개의 숫자를 쓴 글씨   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digits's type is <class 'list'>\n",
      "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n",
      "digits's target name: [0 1 2 3 4 5 6 7 8 9]\n",
      "digits's feature name: ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n",
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "digits = load_digits() # 모듈을 변수에 저장한다.\n",
    "print(\"digits's type is\", type(dir(digits)))   # dir()을 사용하면 객체가 갖고있는 변수와 메서드를 나열한다. \n",
    "print(digits.keys())\n",
    "features = digits.data   # key를 사용해 feature와 label을 변수에 저장한다. \n",
    "labels = digits.target\n",
    "print(\"digits's target name:\", digits.target_names)\n",
    "print(\"digits's feature name:\", digits.feature_names)\n",
    "print(digits.DESCR)    # dataset에 대한 description을 볼 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. split data\n",
    "\n",
    "- sklearn.model_selection 모듈을 사용해 train, test로 데이터를 나눈다.\n",
    "- shuffle=False 파라미터를 설정하지 않으면 기본값으로 랜덤한 값으로 섞어서 나눠진다.\n",
    "- random_state 파라미터를 통해 시드(seed)를 고정시킬 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1437 360\n",
      "1437 360\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=16)\n",
    "\n",
    "print(len(x_train), len(x_test))\n",
    "print(len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 분포확인   \n",
    "    : 고르게 분포되어있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 178,\n",
       "         1: 182,\n",
       "         2: 177,\n",
       "         3: 183,\n",
       "         4: 181,\n",
       "         5: 182,\n",
       "         6: 181,\n",
       "         7: 179,\n",
       "         8: 174,\n",
       "         9: 180})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(digits['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. train with various model\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- SVM\n",
    "- SGD Classifier\n",
    "- Logistic Regression\n",
    "\n",
    "(1) Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91        33\n",
      "           1       0.76      0.72      0.74        36\n",
      "           2       0.86      0.83      0.85        36\n",
      "           3       0.81      0.79      0.80        38\n",
      "           4       0.79      0.84      0.82        37\n",
      "           5       0.80      0.86      0.83        28\n",
      "           6       0.97      0.81      0.88        42\n",
      "           7       0.80      0.95      0.86        37\n",
      "           8       0.72      0.79      0.75        33\n",
      "           9       0.83      0.72      0.77        40\n",
      "\n",
      "    accuracy                           0.82       360\n",
      "   macro avg       0.82      0.82      0.82       360\n",
      "weighted avg       0.83      0.82      0.82       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=16)\n",
    "\n",
    "decision_tree.fit(x_train, y_train)\n",
    "y_pred = decision_tree.predict(x_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능 평가 : accuracy  \n",
    "각 label의 평가 지표가 고르게 분포되어있다.   \n",
    "때문에 전체 정확도를 평가하는 accuracy를 평가지표로 채택하였다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree acc is 0.8222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_pred, y_test)\n",
    "print('decision tree acc is', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       1.00      1.00      1.00        34\n",
      "           2       1.00      1.00      1.00        35\n",
      "           3       0.97      1.00      0.99        36\n",
      "           4       1.00      0.95      0.97        41\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       1.00      1.00      1.00        35\n",
      "           7       0.98      0.98      0.98        44\n",
      "           8       0.94      0.92      0.93        37\n",
      "           9       0.94      0.94      0.94        35\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n",
      "random forest acc is 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=16)\n",
    "\n",
    "random_forest.fit(x_train, y_train)\n",
    "y_pred = random_forest.predict(x_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_pred, y_test)\n",
    "print('random forest acc is', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- classification report에서 accuracy, macro avg, weighted avg모두 동일하게 나왔고, 분포가 고르다고 판단돼 accuracy로 평가하였다. \n",
    "\n",
    "\n",
    "(3) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       1.00      0.97      0.99        35\n",
      "           2       1.00      1.00      1.00        35\n",
      "           3       1.00      1.00      1.00        37\n",
      "           4       1.00      1.00      1.00        39\n",
      "           5       1.00      1.00      1.00        30\n",
      "           6       1.00      1.00      1.00        35\n",
      "           7       0.98      1.00      0.99        43\n",
      "           8       0.97      0.97      0.97        36\n",
      "           9       0.97      0.97      0.97        35\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "svm model acc is 0.9916666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm = svm.SVC()\n",
    "\n",
    "svm.fit(x_train, y_train)\n",
    "y_pred = svm.predict(x_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_pred, y_test)\n",
    "print('svm model acc is', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       0.91      0.82      0.86        38\n",
      "           2       1.00      1.00      1.00        35\n",
      "           3       0.97      0.95      0.96        38\n",
      "           4       0.95      0.97      0.96        38\n",
      "           5       0.93      0.97      0.95        29\n",
      "           6       0.91      1.00      0.96        32\n",
      "           7       0.91      1.00      0.95        40\n",
      "           8       0.94      0.92      0.93        37\n",
      "           9       0.97      0.89      0.93        38\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n",
      "sgd classifier acc is 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import  SGDClassifier\n",
    "\n",
    "sgd_classifier = SGDClassifier()\n",
    "\n",
    "sgd_classifier.fit(x_train, y_train)\n",
    "y_pred = sgd_classifier.predict(x_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_pred, y_test)\n",
    "print('sgd classifier acc is', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       0.97      0.89      0.93        37\n",
      "           2       0.94      1.00      0.97        33\n",
      "           3       0.97      1.00      0.99        36\n",
      "           4       0.95      0.90      0.92        41\n",
      "           5       0.97      0.94      0.95        31\n",
      "           6       1.00      1.00      1.00        35\n",
      "           7       0.91      0.98      0.94        41\n",
      "           8       0.92      0.92      0.92        36\n",
      "           9       0.97      0.97      0.97        35\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n",
      "logistic regression acc is 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_regression = LogisticRegression(max_iter=5000)\n",
    "\n",
    "logistic_regression.fit(x_train, y_train)\n",
    "y_pred = logistic_regression.predict(x_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_pred, y_test)\n",
    "print('logistic regression acc is', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# project(2). wine classification\n",
    "## 01. load dataset \n",
    "- 모듈을 import해서 dataset을 가져온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine's type is <class 'list'>\n",
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])\n",
      "wine's target name: ['class_0' 'class_1' 'class_2']\n",
      "wine's target name: ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()\n",
    "print(\"wine's type is\", type(dir(wine)))\n",
    "print(wine.keys())\n",
    "features = wine.data\n",
    "labels = wine.target\n",
    "print(\"wine's target name:\", wine.target_names)\n",
    "print(\"wine's target name:\", wine.feature_names)\n",
    "print(wine.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. split data\n",
    "- starify 파라미터    \n",
    "    : 데이터의 분포가 고르지 않아서 몇 모델에서의 결과가 정상적으로 출력되지 않았다.   \n",
    "     때문에 설정한 변수에 대한 비율을 동일하게 split해주는 starify 파라미터로 label간 분포를 일정하게 유지시켰다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142 36\n",
      "142 36\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, \n",
    "                                                    random_state=16,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "print(len(x_train), len(x_test))\n",
    "print(len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 분포 확인   \n",
    "    : label간 분포의 차이가 있다. 분포가 고르지 않다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 59, 1: 71, 2: 48})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(wine['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. train with various model\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- SVM\n",
    "- SGD Classifier\n",
    "- Logistic Regression\n",
    "\n",
    "(1) Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        13\n",
      "           1       0.86      1.00      0.92        12\n",
      "           2       1.00      0.91      0.95        11\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.95      0.94      0.95        36\n",
      "weighted avg       0.95      0.94      0.95        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "\n",
    "decision_tree.fit(x_train, y_train)\n",
    "y_pred = decision_tree.predict(x_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree acc is 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_pred, y_test)\n",
    "print('decision tree acc is', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       0.93      1.00      0.96        13\n",
      "           2       1.00      0.91      0.95        11\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.97      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "random forest acc is 0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "\n",
    "random_forest.fit(x_train, y_train)\n",
    "y_pred = random_forest.predict(x_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_pred, y_test)\n",
    "print('random forest acc is', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능 평가 : accuracy  \n",
    "decision tree와 random forest는 데이터의 분포가 고르게 나타났다.(**support**는 각 label당 데이터의 개수를 나타낸다.)   \n",
    "때문에 정확도를 평가하는 **accuracy**를 사용해 평가하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88        13\n",
      "           1       0.71      0.67      0.69        15\n",
      "           2       0.40      0.50      0.44         8\n",
      "\n",
      "    accuracy                           0.69        36\n",
      "   macro avg       0.68      0.67      0.67        36\n",
      "weighted avg       0.72      0.69      0.70        36\n",
      "\n",
      "svm model acc is 0.6944444444444444\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm = svm.SVC()\n",
    "\n",
    "svm.fit(x_train, y_train)\n",
    "y_pred = svm.predict(x_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test, zero_division=0))\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_pred, y_test)\n",
    "print('svm model acc is', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88        13\n",
      "           1       0.71      0.67      0.69        15\n",
      "           2       0.40      0.50      0.44         8\n",
      "\n",
      "    accuracy                           0.69        36\n",
      "   macro avg       0.68      0.67      0.67        36\n",
      "weighted avg       0.72      0.69      0.70        36\n",
      "\n",
      "svm model weighted f1 score is 0.7038995317156237\n"
     ]
    }
   ],
   "source": [
    "# svm = svm.SVC()\n",
    "\n",
    "svm.fit(x_train, y_train)\n",
    "y_pred = svm.predict(x_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test, zero_division=0))\n",
    "\n",
    "weighted_f1_score = metrics.f1_score(y_pred, y_test, average='weighted')\n",
    "print('svm model weighted f1 score is', weighted_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85        14\n",
      "           1       0.86      0.67      0.75        18\n",
      "           2       0.40      1.00      0.57         4\n",
      "\n",
      "    accuracy                           0.75        36\n",
      "   macro avg       0.72      0.82      0.72        36\n",
      "weighted avg       0.83      0.75      0.77        36\n",
      "\n",
      "sgd classifier weighted f1 score is 0.7675518925518925\n"
     ]
    }
   ],
   "source": [
    "sgd_classifier = SGDClassifier()\n",
    "\n",
    "sgd_classifier.fit(x_train, y_train)\n",
    "y_pred = sgd_classifier.predict(x_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test, zero_division=0))\n",
    "\n",
    "weighted_f1_score = metrics.f1_score(y_pred, y_test, average='weighted')\n",
    "print('sgd classifier weighted f1 score is', weighted_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능 평가 : weighted f1 score\n",
    "와인을 분류하는 task는 거짓 긍정, 거짓 부정보다 전반적인 정확도가 더 중요하다.  \n",
    "때문에 정확도(accuracy) 혹은 정밀도(presision)와 재현율(recall)의 평균인 f1 score를 평가 지표로 채택하려 한다.  \n",
    "**svm model**과 **sgd classifier**에서는 데이터의 분포가 치우쳐져 있기 때문에,  \n",
    "데이터 분포에 따른 가중치를 적용한 **Weighted f1 score**를 최종적인 평가 지표로 채택하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        13\n",
      "           1       0.86      1.00      0.92        12\n",
      "           2       1.00      0.91      0.95        11\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.95      0.94      0.95        36\n",
      "weighted avg       0.95      0.94      0.95        36\n",
      "\n",
      "logistic regression acc is 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression(max_iter=5000)\n",
    "\n",
    "logistic_regression.fit(x_train, y_train)\n",
    "y_pred = logistic_regression.predict(x_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_pred, y_test)\n",
    "print('logistic regression acc is', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# project(3). breast cancer classification\n",
    "## 01. load dataset \n",
    "- 모듈을 import해서 dataset을 가져온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer's type is <class 'list'>\n",
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n",
      "cancer's target name: ['malignant' 'benign']\n",
      "cancer's target name: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "print(\"cancer's type is\", type(dir(cancer)))\n",
    "print(cancer.keys())\n",
    "features = cancer.data\n",
    "labels = cancer.target\n",
    "print(\"cancer's target name:\", cancer.target_names)\n",
    "print(\"cancer's target name:\", cancer.feature_names)\n",
    "print(cancer.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455 114\n",
      "455 114\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, \n",
    "                                                    random_state=16, stratify=labels)\n",
    "\n",
    "print(len(x_train), len(x_test))\n",
    "print(len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 분포 확인   \n",
    "    : 데이터가 살짝 치우쳐져있다. \n",
    "- stratify=labels로 label의 분포를 동일하게 설정하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 212, 1: 357})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(cancer['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. train with various model\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- SVM\n",
    "- SGD Classifier\n",
    "- Logistic Regression\n",
    "\n",
    "(1) Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        42\n",
      "           1       0.92      0.92      0.92        72\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.89      0.89      0.89       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "decision tree recall is 0.8947368421052632\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=16)\n",
    "\n",
    "decision_tree.fit(x_train, y_train)\n",
    "y_pred = decision_tree.predict(x_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "\n",
    "recall = metrics.recall_score(y_pred, y_test, average='weighted')\n",
    "print('decision tree recall is', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[36,  6],\n",
       "       [ 6, 66]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91        37\n",
      "           1       0.99      0.92      0.95        77\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.92      0.95      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "random forest recall is 0.9385964912280702\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(random_state=16)\n",
    "\n",
    "random_forest.fit(x_train, y_train)\n",
    "y_pred = random_forest.predict(x_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "\n",
    "recall = metrics.recall_score(y_pred, y_test, average='weighted')\n",
    "print('random forest recall is', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[36,  6],\n",
       "       [ 1, 71]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88        33\n",
      "           1       1.00      0.89      0.94        81\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.89      0.94      0.91       114\n",
      "weighted avg       0.94      0.92      0.92       114\n",
      "\n",
      "svm model recall is 0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm = svm.SVC()\n",
    "\n",
    "svm.fit(x_train, y_train)\n",
    "y_pred = svm.predict(x_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "\n",
    "recall = metrics.recall_score(y_pred, y_test, average='weighted')\n",
    "print('svm model recall is', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.78      0.85        50\n",
      "           1       0.85      0.95      0.90        64\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.89      0.87      0.87       114\n",
      "weighted avg       0.88      0.88      0.88       114\n",
      "\n",
      "sgd classifier recall is 0.8771929824561403\n"
     ]
    }
   ],
   "source": [
    "sgd_classifier = SGDClassifier()\n",
    "\n",
    "sgd_classifier.fit(x_train, y_train)\n",
    "y_pred = sgd_classifier.predict(x_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "\n",
    "recall = metrics.recall_score(y_pred, y_test, average='weighted')\n",
    "print('sgd classifier recall is', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        42\n",
      "           1       0.96      0.96      0.96        72\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.94      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "logistic regression recall is 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression(max_iter=5000)\n",
    "\n",
    "logistic_regression.fit(x_train, y_train)\n",
    "y_pred = logistic_regression.predict(x_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "\n",
    "recall = metrics.recall_score(y_pred, y_test, average='weighted')\n",
    "print('logistic regression recall is', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  성능 평가 : accuracy\n",
    "전체 데이터를 살펴보면 0, 1 두 label중 1에 조금 치우친 분포를 볼 수 있었다.\n",
    "유방암 데이터셋 특성 상, 악성을 양성이라고 판단하는 것(0을 1로 예측)이 위험하기 때문에 재현율(recall)을 평가지표로 삼고자한다.  \n",
    "또한 label의 분포가 치우쳐져있기 때문에 가중치를 average 파라미터로 적용시켜 평가하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정리\n",
    "---\n",
    "1. 손글씨(digits), 와인(wine), 유방암(breast cancer) dataset을 sklearn모듈을 이용해 load한다.   \n",
    "    - 데이터가 각 label당 고르게 분포하였는지 확인한다.\n",
    "    - 데이터 description을 출력해 해당 데이터의 특성을 파악한다.\n",
    "2. 학습과 평가를 위해 train, test 두 개의 dataset으로 나눈다.   \n",
    "    - 이 때, 시드를 고정시기고, label의 분포를 고정시켜 학습 시 분포를 일정하게 유지하였다.  \n",
    "3. 의사결정트리, 랜덤포레스트, SVM, SGD 분류, 로지스틱 회귀 **총 5개의 머신러닝 모델로 학습**한다.   \n",
    "4. confusion matrix를 확인할 수 있는 classification report를 통해 정밀도, 재현율, f1 스코어를 확인한다.\n",
    "5. 데이터 분포, 특성 등을 총합해 모델의 성능을 평가할 지표를 선택한다.\n",
    "\n",
    "# 루브릭 평가\n",
    "---\n",
    "1. **3가지 데이터셋의 구성이 합리적으로 진행되었는가?**   \n",
    "    - 각 데이터셋을 분석, 모델에 적용, 평가한 내용을 코드의 주석과 위 *#정리* 에 정리하였다.  \n",
    "2. **3가지 데이터셋에 대해 각각 5가지 모델을 성공적으로 적용하였는가?**  \n",
    "    - 데이터의 분포를 고려하지 않았을 때는 wine 데이터셋의 학습에서 특정 label이 전혀 나오지 않아 학습이 되지 않았다.  \n",
    "    - 이를 해결하기 위해 데이터 분포를 고정시키는 **stratify** 파라미터를 적용하여 해결했다.  \n",
    "3. **3가지 데이터셋에 대해 모델의 평가지표가 적절히 선택되었는가?**  \n",
    "    - Counter() 함수로 전체 데이터셋의 분포를 확인하였고, classification report의 support로 테스트 데이터셋의 분포를 재확인하였다.  \n",
    "    - 정밀도, 재현율, f1 스코어에 대한 의미를 파악하고, 각 데이터셋의 특성에 따라 중요도를 판단하였다.  \n",
    "    \n",
    "# 회고\n",
    "---\n",
    "## 새롭게 알게된(혹은 다시 정립한) 개념\n",
    "- **random_state**와 **stratify**의 차이  \n",
    "\n",
    "    (1) random_state  \n",
    "    데이터셋을 train, test로 나눌 때 shuffle=False 파라미터를 설정하지 않으면 자동으로 무작위로 섞게 된다. 여기에서 무작위란 어떤 특정한 숫자로부터 시작한 난수처럼 보이는 수열을 말한다. 수열이 시작되는 특정한 숫자를 시드(seed)라고 하며, 이 시드를 수동으로 설정하고 다음에도 동일한 시드를 사용하면 동일하게 나눠진 데이터를 얻을 수 있다.\n",
    "     따라서 데이터를 섞되 일정하게 섞고 싶을 때 사용하는 것이 seed이고, 이를 설정하는 파라미터가 random_state이다.  \n",
    "     \n",
    "    (2) stratify  \n",
    "    label당 데이터의 분포를 일정하게 고정하는 파라미터이다. 예를 들어 label=[0, 1]이라면, 매 split을 진행할 때마다 70:30의 비율로 고정할 수 있다. ~~비율을 어떻게 정하는 지는 더 공부해봐야겠다.~~ \n",
    "    해당 파라미터는 classification report에서 학습이 제대로 되지 않아 특정 label의 모든 지표와 데이터 개수가 0으로 나오는 바람에 찾아보게 되었다. \n",
    "    \n",
    "\n",
    "- **confusion matrix**와 **평가지표**  \n",
    "\n",
    "    (1) 정밀도(precision)  \n",
    "    정밀도는 예측한 모든 y_pred 중에 정확하게 예측한 값이 어느정도 있는가를 측정한 지표이다. 참과 거짓이 있다면 참이라고 예측한 값들 중 진짜 참은 얼마나 있는가?! 라고 말할 수 있다.  \n",
    "    정밀도를 통해 **우리는 예측하고자 하는 label을 얼마나 정확하게 예측하는지**를 알 수 있다. \n",
    "    \n",
    "    (2) 재현율(recall)  \n",
    "    재현율은 참과 거짓이 있다면 모든 참 중 참이라고 예측한 값이 얼마나 있는가를 측정한 지표이다. 이를 통해 **우리가 예측한 결과가 얼마나 정확한지**를 알 수 있다. \n",
    "    \n",
    "    (3) trouble shooting  \n",
    "    true positive+false posivie==0 이면, 정밀도를 정의할 수 없기에 0으로 출력되고, true positive+false negative==0 이면, 재현율을 정의할 수 없어 0으로 출력된다.\n",
    "\n",
    "\n",
    "## 느낀 점\n",
    "confusion matrix를 이해하고 정밀도, 재현율에 대한 차이를 이해하는 것이 어려웠다. 아직 완벽하게 체화하지 못했지만 앞으로 다른 데이터에도 적용하면서 체화할 수 있을 것이라고 생각한다. 머신러닝 모델을 모듈을 사용해서 세 줄로 학습, 예측, 평가까지 끝낼 수 있다는게 놀라웠고 코드가 짧은 만큼 다양한 파라미터가 있는 것 같다. nn을 사용할 때 loss가 0으로 수렴하는 과정을 보다가 1초도 안되는 시간안에 학습을 끝낸다는 것이 놀라우면서 학습과정을 보지 못해 답답하기도 했다. 또한 데이터의 특성에 따라 성과지표가 다를 수 있다는 것은 매우 중요한 포인트라고 생각한다. 학습 모델을 구축하기 전에 평가지표에 대한 정립을 하는 과정이 필요하다는 것을 배울 수 있었다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
