{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "touched-swift",
   "metadata": {},
   "source": [
    "# [Going Deeper NLP 02] SentencePiece\n",
    "\n",
    "Google에서 제공하는 오픈소스 기반 Sentence Tokenizer/Detokenizer 패키지인 SentencePiece를 사용하는 프로젝트입니다. \n",
    "\n",
    "---\n",
    "\n",
    "## 프로젝트 목표\n",
    "---\n",
    "- 한국어로 구성된 네이버 영화리뷰 감정분석 문제에 SentencePiece를 적용한다. \n",
    "- Unet, generator, discriminator레이어를 구성한다.\n",
    "\n",
    "\n",
    "## 프로젝트 설명\n",
    "---\n",
    "1. 네이버 영화리뷰 감정분석 코퍼스에 sentencepiece를 적용시킨 모델 학습하기\n",
    "\n",
    "2. 학습된 모델로 sp_tokenize() 메소드 구현하기\n",
    "\n",
    "3. 구현된 토크나이저를 적용하여 네이버 영화리뷰 감정분석 모델을 재학습하기\n",
    "\n",
    "4. KoNLPy 형태소 분석기를 사용한 모델과 성능 비교하기\n",
    "\n",
    "5. (보너스) SentencePiece 모델의 model_type, vocab_size 등을 변경해 가면서 성능 개선 여부 확인하기\n",
    "\n",
    "6. Word Vector는 활용할 필요가 없습니다. 활용이 가능하지도 않을 것입니다.\n",
    "\n",
    "7. 머지않아 SentencePiece와 BERT 등의 pretrained 모델을 함께 활용하는 태스크를 다루게 될 것입니다.\n",
    "\n",
    "## 1. 데이터 불러오기 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "rocky-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "import urllib.request\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lonely-gambling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ratings.txt', <http.client.HTTPMessage at 0x7f015c5e5850>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "lovely-drive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
       "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
       "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
       "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naver_df = pd.read_table('ratings.txt')\n",
    "naver_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "centered-photograph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 개수 : 200000\n"
     ]
    }
   ],
   "source": [
    "print('데이터 개수 :', len(naver_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-homeless",
   "metadata": {},
   "source": [
    "### 결측치, 중복 확인 및 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dying-terrorism",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_len = len(naver_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "distinguished-schema",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "document    8\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naver_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "tutorial-citation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame._add_numeric_operations.<locals>.sum of            id  document  label\n",
      "0       False     False  False\n",
      "1       False     False  False\n",
      "2       False     False  False\n",
      "3       False     False  False\n",
      "4       False     False  False\n",
      "...       ...       ...    ...\n",
      "199995  False     False  False\n",
      "199996  False     False  False\n",
      "199997  False     False  False\n",
      "199998  False     False  False\n",
      "199999  False     False  False\n",
      "\n",
      "[199992 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "naver_df = naver_df.dropna(how='any')\n",
    "print(naver_df.isnull().sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ordinary-graham",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측치 제거 후 데이터 개수 : 199992\n"
     ]
    }
   ],
   "source": [
    "print('결측치 제거 후 데이터 개수 :', len(naver_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "worse-passion",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "naver_df.drop_duplicates(['document'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "blank-smoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 데이터 개수 : 194543\n"
     ]
    }
   ],
   "source": [
    "print('중복 제거 후 데이터 개수 :', len(naver_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "committed-breakfast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 전 데이터 개수 : 200000\n",
      "전처리 후 데이터 개수 : 194543\n",
      "전처리 후 남은 데이터 양(%) 97.2715\n"
     ]
    }
   ],
   "source": [
    "print('전처리 전 데이터 개수 :', origin_len)\n",
    "print('전처리 후 데이터 개수 :', len(naver_df))\n",
    "print('전처리 후 남은 데이터 양(%)', (len(naver_df)/origin_len)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "lucky-guidance",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
       "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
       "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
       "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naver_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "contemporary-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "naver_review = naver_df['document']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-squad",
   "metadata": {},
   "source": [
    "### 데이터 분석 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "designed-mozambique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 142\n",
      "문장의 평균 길이: 36\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "for sen in naver_review:\n",
    "    length = len(sen)\n",
    "    if min_len > length: \n",
    "        min_len = length\n",
    "        \n",
    "    if max_len < length: \n",
    "        max_len = length\n",
    "    \n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(naver_review))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in naver_review:\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-credit",
   "metadata": {},
   "source": [
    "**최장 길이 142에 가까운 데이터가 꽤 많습니다. 어떤 문장인지 확인해봅니다.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "tracked-moral",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "내가 남자라그런가 이거 겁나 긴장감있고 흥미진진하던데..ㄷㄷ 나만그런가워낙에 격투씬을 좋아해서.ㅋㅋㅋ 그냥 아무생각없이 집에서 스마트티비로 봐서 재밌었나봄 이거 뭔영화인지도 모르고 암살에 나온 이정재 있길래 걍봄 ㅋㅋ 하여튼 너무 재밌게 봤음\n",
      "줄리아 로버츠의 웃음은 정말 보는 사람을 기쁘게 해준다. 웃음 하나로 기쁨과 슬픔을 표현할 수 있는 배우..전통을 깨고 여성의 새로운 삶을 살으라고 영화는 보여주는 데 영화에서는 전통을 완전히 벗어나야 한다는 것만을 강조하는 것 같아 아쉽다.\n",
      "평점 왜 이렇게 낮아요??? 영화 대박인데...진짜....ㅋㅋㅋ 와.. 어떻게 이런상상을 해서 이런 영화를... 대박대박.. ㅠ 생각지못한 반전.. 처음엔 반신반의하면서 봤는데.. 최고내요...ㄷㄷㄷ 근데 금발 여주는 중반에 좀 짜증나긴했음ㅋ\n",
      "큰 기대 안하고 띄엄띄엄 보다가 집중해서 봤네요!! 저는 잘봤습니다. 액션도 뛰어나고 아슬아슬한 장면들을 극복해 가는게 나름 잼있었어요!! 마지막에 여자 박사가 살았는지 죽었는지가 안나와서 좀 아쉽네요..그래도 딸은 살렸으니 다행스럽다는 ㅎㅎ\n",
      "누군가는 잃고, 누군가는 벌고, 또 누군가는 죽는 게임. 그리고 끊임없이 반복되는 삶과 기억의 굴레. 하지만 시작할 때부터 영화는 이미 심각했고, 지루했다. 다 본 후 생각해보니 그럴 수밖에 없었겠다 싶다. 넓고 얕은 재미, 길고 깊은 여운.\n",
      "영화내용은 사실별거 없지만 보고나면 생각을 많이하게 되는 영화임. 재미있기도 하고, 결론은 무엇이냐 하면 빨갱이들이 아무것도 모르는 사람들 선동해서 비참한 결과를 낳게 한다는 내용임. 복수심에 불타는 이북출신들도 나오는데 다 역사적인 사실임.\n",
      "고등학교때 보고 지금에서 생각난 영화 참~그땐 눈물 콧물 흘리면서 봤는데짐 보면 나올라나.. 하긴 세월이 많이 흘렀지 아마 짐 시대하곤 스토리자체가 뻔하니깐 하지만 지금도 잊혀지지않는장면은 주인공이 공부하는장면과하늘도 갈라놓지 못한 그들의사랑\n",
      "오스카는 흔히 볼수있는 아들이자 장난끼 많은 오빠 그리고 항상 미안해하는 남편. 감정이 앞서서 문제를 만들수도 있지만 언제나 마음은 내 가족, 내 사랑인 그 한사람. 정말 거지같은 상황속에서도 사랑이라는 한 단어로 살아남으려는 자를 짖밟았다.\n",
      "올타쿠나커플때문에 다시 우결 보게됬어여제가 소은이같은 성격이라 너무공감되고 설레여~소은씨는 드센게 아니라 남자를 잘 맞춰주고 흡수하는 스펀지같은 여자에요^^그리고 재림씨 자기마음을 다 말해주는 재림씨 너무짱~~~정말 오빠,아빠, 애기같은 매력\n",
      "오히려 평점 조작같은데.. 감독이 충무로 미움 삿을수도 있다는 생각까지 든다...한국영화 별로 좋아하진않지만.. 이영화가 이렇게까지 평점낮을만큼 재미없진 않다. 이정도 평점의 다른 영화같지않은 영화들과 비교할때 이 평점은 이해가 되질 않는다.\n",
      "이루어 질수 없기에 더욱 너무나 애절하고 안타까운 야하기만 한게 아니라 너무나 아름다운 영상. 그리고 소녀를 사랑하는 마음을 이룰 수 없는 중국인 청년의 안타깝고 애절한 눈빛. 소녀와 여인의 경계에 있는 제인마치도 너무나 묘하게 잘 어울린다.\n",
      "구작보다 묵시록적이고 웅장해짐. 아스카의 심리묘사가얇아지고 당위성이 부족해지는등의 단점이 있음에도 불구하고 현세대최고의 애니메이션중 하나임. 특히 영상미는 TVA판을 압도하고도 남을정도. 사골이아닌 새로운 스토리가 추가됫는데 굉장히 만족스러움\n",
      "오카다 마사키는 풋풋한 멜로에 정말 잘어울리는듯하다. 뭔가 첫사랑같은 느낌? 설레는 느낌을 주는 배우. 일본 멜로의 잔잔함이 이 영화에서도 드러난다. 청소년의 학업과 사랑 사이에서의 갈등도 무각본인만큼 자연스레 연기하여서 더욱 공감하며 봤다.\n",
      "이병우 작곡가의 곡들이 담긴 영화를 볼 때마다 느끼지만,이렇게 공포영화 음악을 아름답고 절묘하게 만드는 작곡가는 잘 없는 것 같다.한국 공포영화의 특징은 배경과 어우러지는 음악적 요소인데,이 작곡가가 어떻게 보면 그 처음이라고 볼 수 있겠다.\n",
      "지금 알고 있는걸 그때도 알았더라면... 내 가슴이 말하는 것에 더 자주 귀 기울였으리라더 즐겁게 살고 덜 고민했으리라사랑에 더 열중하고 그 결말에 대해선 덜 걱정했으리라.. 설령 그것이 실패로 끝난다 해도.... 웅... 너무 늙어서 봤다~\n",
      "인종차별과 불평등은 미국만의 문제가 아니다. 영웅적인 지도자가 아니라 서로 도와주려는 사람들의 연대감이 역사를 바꾼다는 것을 매우 사실적으로 보여준 영화다. 새로 알게 된 사실은 FBI가 킴 목사의 일거수일투족을 샅샅이 감시하고 있었다는 것.\n",
      "난 남자고 저 딸의 아비라면 저 김윤진 역보다 더 한 것도 할 수 있고 그 어미니의 아들입장이라면 저보다 더 한 것도 할 수 있다.. 평만보면 다들 공자시구만ㅋㅋㅋ 과연 정말 저 둘의 배역 중 하나의 입장이 된다면 그렇게 냉정할 수 있을까..\n",
      "뻔하고 진부하지만 그로인해 더 편안하고 행복한 결말. 나에게 있어 한국영화를 다시보게 만든 영화. 30대인 지금. 영화의 개봉 당시 10년 전으로 돌아가서 나의 무지개를 찾고 싶다.ps : 여태 본 영화중에 카메라에 빛을 가장 잘 담은 작품.\n",
      "This movie wowed and shocked me! 대학시절 과학사를 들었어도 이렇게 포괄적이고 모든 분야를 넘나드는 이해력을 갖을 수는 없었는 데. 융합적 사고의 총체! 초등학교에서 부터 대학교에 이르기까지 교양필수로 강추. 초강추.\n",
      "그저그런 로맨틱 코미디가 아닙니다~로맨틱 코미디도 프랑스에서 만들면 이렇게 멋진 영화가 나오는 군요 ㅋㅋ 문화를 주도해 나갔던 유럽인들의 풍속사를 잘 재현해 내었네요~ 코디디는 기본이구요! 이놈의 망할 제목때문에 안 뜬 영화 같습니다. -_-\n",
      "윤재문보다 인구아재의 딸과 마누라가 더 얄밉더라 고기만두사왔는데 휙 지나치는장면, 그동안 깡패짓으로번돈 잘써놓고선 한번도 떳떳한적없었다고말하는 마눌년 송강호가 울먹이면서 당신은 이러면안되지 라고할땐 울컥했다범죄영화가아니라 가장영화 아버지영화다\n",
      "같은 영화를 본다고 해도 내가 느낀 내가 받은 영향은 분명다르다. 이런 영화는 항상 뭔가 열어놓았기에,. 한 번씩 다시 보면 지난날의 나 혹은 앞으로의 나를 볼 수 있기도 하다., 또한 모든 아픔의 극복은 스스로 할 수 있게 놔두는게 좋다.,\n",
      "난 중국영화를 좋아하지만 천녀유혼은 5번밖에 안봤다. 어릴때라 영화에 대해 무지해서 명절때 누나가 보는걸 따라봤다. 하지만 20대가 되고나서 그시절 왜 장국영, 왕조현이 넘사벽인지 이영화를 보고 느꼈다. 왕조현 장국영은 아시아최고라 생각한다.\n",
      "스크린 너머로 배려심이라곤 없는 감독을 만나 개고생하는 두 여배우의 고통이 느껴졌다. 예술의 완성도가 꼭 극단으로 몰아부쳐야 완성되는가. 레아세이두의 말대로 존중만 해줬어도 진짜 완벽한 작품이 나오지 않았을까. 배우들의 노고때문에 10점이다.\n",
      "정말 미친듯 웃을 수 있어요~ 몰랐던 역사적 사실도 알게되고~출연자분 스텝분들 고생 많으시겠어요제 8의 멤버 이윤상님 나오실 때마다 웃겨요연기력에 감탄도 하게되고그리고 역시 정말 장동민 최고!!!시즌2 2번째 촬영에 콩이 또 나와서 즐겁습니다\n",
      "범죄없는세상 외치면서 그런사람들이 더하네 칭찬은 고래도 춤추게 한다 성지고 고생했다 한마디면 되는걸 한번도 못놀아본 사람 처럼 클럽,술 마신거 가지고 좀그러네 그건 뒷풀이야 방식이 다른것 뿐이지 자라나는 새싹 밟지말고 자신부터 돌아보고 잘하자\n",
      "연출력이 상당히 돋보이는 작품이다. 할배가 할매를 질식사 시킬 줄은 꿈에도 예측 못했다. 정말로충격적인 장면이었다. 할매가 나중에 어떻게 인생이 마감 할까? 내가 짐작하는바가 있었는데 갑자기 자기손으로할매를 보내다니...씁씁하기 그지 없었다.\n",
      "상당히 오래만든 만화임에도 잘만들었고 철학적 잔인함 여러성적 표현 이것은 다분한 우리 인생을 묘사하고 있다 베르세르크야 말로 우리 무뎌진 머리를 환상속에 빠져들게 만든다 판타지의 최고봉 애니를 적당하게 봐왔지만 이보다 나은 애니는 첮기 힘들다\n",
      "처음엔 정신이 피폐해진것같아 불쾌했다. 막연히 걱정하지만 넘겨버릴법한 범죄상황을 실감나고 섬세하게 묘사한 감독이 대단하다... 박진감은 넘치지만 억지상황이 난무해 문단속의 중요성을 잊게 한 불사여인의 비현실 영화 '숨바꼭질'이 문득 생각난다.\n",
      "수작이라고 평가한다. 보는 내내 긴장감과 궁금증을 유발하는 내용이며, 공포감과 스릴도 공존한다. 배우들의 연기도 전혀 위화감 없이 흘러간다. 다만 후속편은 굉장히 유치해졌으므로, 후속편은 보지 않는 걸 추천한다. 전 작품의 질까지 떨어뜨린다.\n",
      "역시 토이스토리. 재미있고 감동적일 뿐 아니라 현재만을 생각하는 21세기에 사는 우리에게 향수를 느끼게 하고 가끔은 잠시 모든 일을 내려놓고 어렸을 때 가지고 놀았던 장난감들을 생각하며 추억에 젖는 것도 나쁘지 않겠다고 생각하게 하는 영화다.\n",
      "감독님! 상업영화로 평가받고 싶지 않으면 혼자 영원히 습작하세요~ 가족끼리 친구끼리 오순도순 화기애애한거 스스로도 상업성에어 자유로울수 없으면서 쿨한척 하지맙시다. 그런상처 두려우면 투자받지도 마시고 학생들 데리고 작품전같은거 하시면 됩니다.\n",
      "부모님...특히 시부모님이 홍보관가서 사기당했다고 하소연하시는 분들~~~이 영화 꼭 좀 보셨으면좋겠어요..저도반성많이했네요...ㅜㅜ...솔직히 사회나와서 가정도 꾸리고하다보면 자기부모한테 소홀해지는사람많자나요~너무어르신들만 탓할수없을거같아요.\n",
      "요즘들어 다시보니 참 좋은영화다.길용의오토바이 뒤에 타며 고향얘기하는 신은경.참 슬프고 그림같은장면.길용역의 한정현씨라는분은 여기서 주연으로 나오는데 참 역할과 잘어울린다는 생각이.그이후의 작품은 거의 무술단역이고 더 비중있는 모습봤음 아깝네\n",
      "이 영화보면서 재미업다는 사람들은 역사좀 알아라영화에서 왜5.16을등장시키고 최규식 왜거론하는지 알지도못하니 그러지.. 한 남자의 인생을통해서 그시대적 상황을 알수있고 또 제목처럼 한남자가 그런상황에 맞춰 어뜩해 살았는지.. 보는 내내짠햇다.\n",
      "선라이즈 보고 이어서 봤는데 몰입감은 선셋이 좀더 좋은거 같고 작품성은 선라이즈가 나은듯 렛미싱유~♪ 3편 평점보다가 내용을 좀 알아버려서 아쉬움이.. 평점 안보고 볼껄... 사랑을 추억하는 영화 설레임 연애 애틋함이 느껴지는 좋은 영화였다.\n",
      "최근 보기드문 가족영화인 것 같아요!!보수적인 나도 애들의 천진스러운 생각과 가족에 대한 애듯한 사랑의 표현들에 나도 모르게 눈가에 눈물이 주르르 흐르더라고요! 다셋 ,여섯번정도..,저는 시사회에 두번 봤는데 , 두번째는 아들하고 함께봤어요!\n",
      "외모가 부각되어, 단순히 외모가 흉해서 몬스터인 줄 알았다. 그녀는 몬스터가 되었다. 점점 살인을 정당화해가는 모습이 이미 몬스터가 되었단 증거가. 하지만, 그녀를 그렇게 만든 몬스터가 있지 않았다면, 그녀도 이런 삶을 보내진 않았을 것이다.\n",
      "정말 재미있어요!!! 정말로정말로!!레나정은 딸을 빼앗기고 서인철박사가 집사?한테 주고키웠더니 나중엔 알게되서 레나정이 엄마가되고 TNC그룹 장남이 레나정과 결혼하고 장남의 동생인 박재준과 레나저의 딸과 결혼하고? 복잡하지만 재미있어요!!~~\n",
      "한국 영화 보면서 일케 웃어본적 몇년만인거 같네요 ㅋㅋㅋ 뭐 사람들 클라라 벗는 거만 생각하고 봤다가 실망해서 평점 1 주고 햇더만 전 원래 클라라 누군지 잘 몰라서 그냥 영화만 봣는대 웃겨서 ㅋㅋㅋ 팬티 입고 축구장간거에서 빵 터졋다는 ㅋㅋ\n",
      "지금 이 10점은 시즌 1을 위한것에 불과하다. PD도 대단했고, 그때 출연했던 강호동, 이승기, 은지원, 김종민, MC몽, 김C 등 호흡이 척척 맞았다. 물론 지금 안 맞는건 아니지만서도 웬지 모르게 시즌 1이 무척이나 그리운건 나 뿐인가?\n",
      "Mary Hopkin 의 Voyage of the Moon 이 흐르며 새하얀 커피잔에 커피와 독약이 함께 녹는다. 흠 잡을 곳이 없는 멋진 드라마.. 흡사 히가시노게이고 소설의 마무리를 보는 것 같았다. 죽어가는 채령의 모습은 오래 기억될듯.\n",
      "타계하신 배우,윤인자 님께서 주연으로 열연을 보여주신 당시 우리 영화로는 보기드문 수작이라고 기억합니다.오래전, 극장에서 본 영화라서 기억은 가물 대지만 ,전편에 잔잔하게 흐르는 음악도 좋았었구요...윤인자 님의호연이 참,좋았다고 생각합니다.\n",
      "쑨원의 삶을통해 신해혁명의 의미를 되새기고, 중국의역사를 알기쉽게 전달해준 감명깊은 영화였다., 공산당이라고 까는사람들은 중국이 원래는 공산당이 아니었다는사실을알아야한다. 신해혁명은, 청나라에대항해 한족이 일으킨혁명이며 공산당과는전혀상관이없다\n",
      "6점대는 아닌거 같다..곽경택영화는 항상 부담스럽긴 한데.. 겉멋 보다는 툭툭 던지는 욕설 섞인 구수한 사투리의 강한남성영화인거 같다. 출현 배우의 능력을 최대한 끌어내는 감독. 취향은 아니지만 영상 음악 나무랄데 없고 항상 대작스멜이 난다.\n",
      "마고가 루와 그의 가족과 있을때 중간중간 보여줬던 묘한 표정들 .. 외로워보이기도 하고 체념하는듯해보이기도 했는데 결국 마고가 루를 떠났던건 채워지지않는 외로움이 있어서가 아닐까 싶어요. 하지만 새로운 사랑도 이 외로움을 채워주지못한것같아요.\n",
      "오랜만에 보는 서부극.소재도 독특하고 음악역시 특이하게 가스펠을 편곡해서 썼는데, 색다르네. 배역도 좋았고,개인적으로 제프 브리짓스의 가래낀 목소리싫어하는데,헤일리스테인벨트 보는 맛에 참을 수 있었네. 오랜만에 보는 코엔형제작품, 강추합니다.\n",
      "최민식씨가 소주 한잔 하면서 우는장면에서뭐랄까... 아이들을 지키고 싶어하는 선생님의 모습을. 우리 아버지의 모습을. 또 점점 나이가 들어가면서 약해져가는 내 모습을 보는것 같아. 같이 울고 같이 힘내게 되네요. 위로 받았습니다. 감사합니다.\n",
      "인간이 '목적하'에 복제 인간을 만들어 낸다면 현실 가능성 있는 얘기 같다. 복제인간 관점에서 해피엔딩을 바라고 만족감을 바란다면 비추나 힘없고 나약한 그들의 존엄성도 동등히 존중받아야 하는 영혼을 가진 존재란 걸 느끼며 괜찮게 본 영화였다.\n",
      "창업을 꿈꾸는가! 좋은 아이템이 있어 사업을 하려하는가!! 그렇다면 기를 쓰고 이 영활 보기바란다!! 그 멀고 험한 여정에 스승이 될것이요 지침서가 될것이다... 혹은 단념에 도움이 될지도... 참 오랜만에 박장대소하며 본 독립영활세~~~ ★\n",
      "초등학생때 우연히 엄마 가곡집에서 가사를 보고 비디오를 빌려 본 사운드 오브 뮤직은 고등학생때까지?일년에 두번씩 꼭 챙겨보는 인생영화가 되었다. 아름다운 노래소리와 연출들.. 영화의 모든 ost가 이렇게 좋을수 있을까? 볼때마다 소름이 돋는다\n",
      "아주 개만도 못한 인간찌질이들이 악플다네ㅋㅋ 난 잼있게봤는데...영화는 말그대로 그냥 재미있으면 그만인거지..ㅋㅋㅋㅋ 이영화 악플달고 ㅈㄹ 하는 개 만도 못한 인간 찌질이 막장 인생들아.....ㅋㅋ 그냥 목 메러가라 OO 버려라 그냥 ㅋㅋㅋㅋ\n",
      "이영화를 우연히 보게 되고난후 난 너무 아름다웠다. 제작년 추석 TV에서 틀어준 봄여름가을겨울을 우연히 술이 꺤 직후 보게 되었고 난 아름다운 충격에 휩쌓였다. 그런데 그것도 김기덕의 영화였다. 난 이제 알았다. 김기덕은 대단하다는 것을...\n",
      "I am that I am. WHO MADE MAN'S MOUTH? WHO MADE THE DEAF, THE MUTE, THE SEEING OR THE BLIND? DID NOT I? NOW GO! you shall DO MY WONDERS!\n",
      "이 영화를 몇 번이고 보면 볼수록, 하나의 문장이 머릿속에서 떠나질 않았다. 한국은 관객을 위한 영화가 없다. 제발 우리나라 영화가 같잖은 억지눈물샘만 자극하는 돈만 보는 거지같은 거 그만하고 이 영화의 반 정도만 되는 영화를 만들길 바란다.\n",
      "한국 애니메이션을 진심으로 응원합니다. 박신혜씨는 억양이며 말투가 너무 어색하던데 아마 본인도 그 어색함을 느꼈을 듯. 반대로 송창의씨는 정말 자연스럽더군요. 성우인줄 알았는데 영화정보를 보고 알았네요. 오랜만에 보는 한국적인 애니메이션영화.\n",
      "아무도 지킬 생각도 없는 번들어진 규범과 규칙 따위가 대체 무슨 소용이 있나. 다들 기품있고 우아한 척 하지만 기실은 상-놈들이랑 하등 다를 바 없던 우리의 잘나신 나으리들이여. 영화의 모든 것을 장악하고 통제해낸 위대한 르누아르에게 경배를!\n",
      "오랜만에 영화보고 울었다.자이언트가 어디서 무슨목적으로 지구에 왔는진 중요하지 않다. 자이언트는 올바른 길을 선택했고 슈퍼맨이 되었다. 결국 상황이 어떻든 내가 옳은 판단을 하면 되는거다. 이렇다 변명따위 필요없이 나는 내가 선택한대로 된다.\n",
      "영어 잘 못 하는 분들이나 Skype 이용 안 해본 사람한테는 재미 없을 겁니다. 하지만, 연출, 플롯, 영상 등 작품성으로 보면 아주 훌륭한 작품입니다. SNS를 이용하는 모두가 꼭 반드시 봐야 된다고 생각합니다. 친구들한테도 추천해주세요.\n",
      "이 영화에 나오는 잔인한 부분은 시각적으로 자극을 줄려고 만든 것이 아니라 영화가 전달하고자 하는 부분들을깊게 나타내기 위한 요소로 느껴져서 너무 좋앗습니다. 고통이 가지는 의미 전쟁의 참혹함.. 마지막 부분의 여운은 정말.... 최고네요ㅜㅜ\n",
      "잠수함이 부상할때 나오는 마초적인 음악은 정말 남자의 가슴을 흥분시킨다. 잠수함이라는 특수한 공간의 폐쇄성을 지극히 사실적으로 살린 수작 중의 수작!!! 아무리 헐리웃의 CG특수효과가 대단하다하지만 아날로그의 감성을 절대 이길 수는 없지...\n",
      "생각보다 재밌는데 왜 평점이 낮은지 이해가 안된다. 박하선의 연기가 일품이고....특히 여고생연기, 음치흉내내는것 등등 박하선의 매력에 푹~ 빠지게 만드는 그런 영화다....요즘 유머코드와 안맞아서 흥행실패한지는 모르겠지만....암튼 재밌음.\n",
      "브로드웨이에서 직접 보고 영화로 또 봤지만 역시 최고의 감동! 말이필요없네요!! 연출도 훌륭했고 영화는 또 영화만의 매력이 있고 황홀한 음악과 화려한 볼거리로 가득했던 The Phantom of the opera!! Phantastic!!!!\n",
      "신랄하게 주고받는 악담도 재치터지고 가끔씩 폐부를 찌르는 교훈이라고 해야하나 느낀점이라고해야하나 그런것도 감탄을 하게 만듦무엇보다 인물이 너무 생생해서 좋다대사하나하나에 그인물이 물씬 물씬 느껴진다굉장히 생동감있는- 색채가 화려한 대사들이었다\n",
      "28일후는 단순한 좀비영화가 아니라 인간의 본성이 무엇인지, 그리고 집단적 폭력과 비합리적인 권위가 얼마나 위험한 것인지(심지어 좀비보다도)를 보여주려고 한 영화다. 조지 로매오의 살아있는 시체들의 밤과 더불어 좀비 영화의 명작이라고 생각함.\n",
      "Com-아끼고 아껴보던.. 정말.. 명작.. 주옥같은 그 당시 노래와.. 소품들.. 그리고.. 기대치 않았던.. 신인배우들의 연기력... 깨알같던.. 까메오 출연과.. 실타래 풀리는 듯한 스토리가.. 회를 거듭할수록 기대하게 하는 명작 드라마\n",
      "1박2일 시즌1은 그야말로 레전드라 할 수 있겠다. 구성, 출연진, 패턴, 시간대, 조합 등등 모든것이 최고였고, 시청률 역시 40%는 그냥 쉽게쉽게 찍었었지...강호동, 이수근, 은지원, 김종민 참 대단했지...MC몽 병역연기사건이후 하락세\n",
      "인격의 다양한 면을 감각적으로 표현한 멋진 작품. 차안에서의 하가안과 고지위의 동행장면과 마지막에 겁쟁이를 한번더 추악하게 만든 장면 등에서 눈에 보이는 것 이상의 디테일한 세상을 가시적으로 전달하여 상황을 더 인상적이게 표현한 것이 좋았다.\n",
      "작품성, 현실성으로 승부해야 할 다큐무비였다. 한국에 수입되며 상어나오는 B급 여름 스릴러처럼 마케팅해 커플들이 껴안을생각으로 영화관 갔다가 뒤통수 맞으니 환불이나 요청하지. 조난에 대한 현실성은 10점을 줘도 아깝지 않은 안타까운 수작이다.\n",
      "무지한 사람들이 보기에는 덜떨어진 패러디물, 하지만 자세히 찾아보면 사회풍자와 멋드러지게 잘꾸며진 외면 내부에 숨겨진 추악한 부분을 들춰낸다는 깊은 메세지를 담은 영화. 무작정 3류코미디영화라고 생각한다고 본다면 그사람에겐 더이상해줄말이없다.\n",
      "뭐 역사를 다룬영화니 역사왜곡이느니 어쩌구하는 인간들많다 근데 영화는 영화일뿐이고전쟁중에서의 시점은 스파르타시점이니 그 시점에서의 페르시아가 그렇게보인다는 식으로 꾸민건데(적군이고 스파르타 입장이니) 그냥 영화로봐라 영화로 무슨 역사공부하냐?\n",
      "맨 마지막... 강렬했다. 특히 마지막 장면. 어째 슌지는 꼭 자살해서 죽을것 같더라니 ㅠㅠ 우리는 모두 각시탈이고 이 나라의 영웅이다. 우리나라 정말 만세다!! 이번 드라마로 많은 걸 생각한듯.. 교훈과 아쉬움과 뭉클함을 남기고 끝났구나ㅠㅠ\n",
      "장가위감독은 천재다. 대사도 많지 않으면서 관객에게 많은 생각을 하게해준다. 양조위, 장만옥의 연기 또한 일품이다.이 영화를 열번정도 보았는데 다시봐도 질리지 않는 영화로 내겐 고전이 되었다. 음악도 감미롭고, 카메라 워크도 좋았고, 영상미도\n",
      "개인적으로는 에밀리 브론떼의 폭풍의 언덕, 유진 오닐의 밤의로의 기로 같은 작품을 떠올리게 하는 김기덕 감독 식 시나리오의 작품. 이번 작품 또한 오래 오래 생각할 부분이 많을 것 같다. 각본도, 연기도 정말 좋다. 긴장을 놓지 못하고 봤다.\n",
      "독창적이고 종교적 색채(?)가 짙은 영화이지만、맨 프롬 어스와 같이 많은 것을 생각하게 해주는 영화입니다。종교에 대한 생각 자체가 신이 아닌 믿음으로 정의 된다면 상당히 얻어 갈 수 있는 교훈적인 영화이지요~참、좋은 시간이었습니다。강력추천！！\n",
      "이 영화를 단순히 스시에 대한 다큐라고 보지 않으셨으면 합니다ㅋ 일부 전문가들은 이 영화의 전개 등이 뻔하다고 생각 하지만. 이는 감독의 의도를 생각하지 못한 짧은 생각인것 같습니다. 자신의 삶을 이 영화를 거울 삼아 되돌아 보셨으면 합니다.\n",
      "토시오와 가야코가 나와서 무조건 죽이고 다니는, 별 스토리 없는 기존의 주온보다 오히려 더 좋았다. 탄탄한 스토리, 드라마성을 지닌... 새로운 주온으로 거듭날 가능성이 보인다. 좀 안타깝기도 하고 애처롭기도 했다. 꼬마애가 철권날릴때 멋있어\n",
      "난 이런 병맛 같은 영화가 좋다. 매력있는 캐릭터의 집합소이며 어디로 튈 지 모르는 인물들과 스토리에 빠져 들어감. 휘몰아치는 이야기 전개 아니라서 좋고 흔하디 흔한 악역과 갈등 뭐 이런 거 없어서 식상하지 않음. 웃긴데 뭔가 안 웃겨서 좋음\n",
      "톰행크스의 샤프하고차분한연기가 굿.아울러 영화시작과 끝부분에나오는<street of philadelpia>와 <philadelpia>음악은 화룡점정<나는당신의사상에 반대한다.하지만당신이 그사상때문에 탄압을 받는다면 나는당신의편에서서 싸울것이다\n",
      "90년대는 홍콩영화계에 전성기라고 해도 과언이 아닌 시절이죠 그시절에 최고의 여배우들 세명이 나왔던 영화 스토리는 약해도 이러한 영화에 스토리를 찾는 것이 어불성설이지만 진짜 대박이였던 영화 그영화를 다시 리마스터링으로 볼수가 있다니 놀랍네요\n",
      "연기도 스토리도 최괴입니다. 몰입도도 굉장해거 영화애서 눈을 뗄수 없었습니다. 이번 영화로 영국의 역사에도 관심이 생겼네요. 그리고 배우들 연기도 정말 굉장했습니다. 야망에 찬 삶보다는 역시 소박하지만 행복한게 최고라는 생각을 가지게 되었네요\n",
      "케이블tv 에서 우연히 잠깐보고 재미있어 1000원이나 주고 다운받아 보는 중인데, 무한도전이나 개그콘서트도 수준낮다 무시하고 안보는 저이지만 이건 대놓고 코메디인데도 대사들이 인간 본성을 솔직히 드러내 화통하고 재미있습니다. 꼭 한번 보세요\n",
      "극초반에는 다소 억지스러운 설정이다 싶었는데 중반이후부터는 완전 몰입해서 봤습니다. 원작 보다 훌륭한 완성도 그리고 이범수, 정려원의 열연, 열정에 박수 갈채를 보내드리고 싶었고 너무 극전개가 탄탄했고 재미있어서 눈을 뗄 수 없었던 것 같아요\n",
      "내인생 최고의 드라마 라는 수식어가 당연한 최고의 걸작이었다.드라마 끝난지가 5개월이 다 되어가는데도 계속 반복해서 보고있다..매번 흠뻑 빠져서..스토리도 감동이었고 최영장군의 이민호는 최고의 캐스팅이었다.요즘세상 보기드문 감동드라마 신의!!\n",
      "레미제라블을보고, 스위니토드는 생각보다 배우들급이 낮았구나 싶었는데 다시보니 진정한 걸작이다. 가위손 이후 팀버튼과 조니뎁의 시너지가 가장 잘 발현된 작품! 음울한 런던을 표현한 미술에, 손드하임의 탁월한 음악. 주제표현까지 완벽한 잔혹동화!\n",
      "참신하긴해. 헨젤과 그레텔 오누이 가 또 이젠 대한민국으로와갖고, 마녀사냥 접고 일찐 학생들 사냥해주었으면 좋겠다.헨젤과 그레텔이 마녀사냥 때 했던것처럼,,석궁과 총탄으로 일찐 학생들을 송송 벌집 내줬으면 좋겠구나.헨젤과그레텔-일찐학생 사냥꾼\n",
      "이뮤지컬영화에 왜 이렇게 빠졌는지 나도잘 모르겠다. 수도 없이 봐서 이제 내가 이영화를 총 몇번 봤는지 기억도 안난다. 40~50번 정도 본거 같다. 열정 그래 이영화를 보면 열정이 살아 난다. 삶이 힘들때마다 내게 열정을 불어넣어준 \"렌트\"\n",
      "누가 그랬다 20살의 남자는 임신을 보고도 섹스 하는 상상만하지만....자식을 키운 남자는 임산부가 아름답게 보인다고..영화에게 몇년전에 느낀거 보다 더 많은것이 느껴진다..보면 볼수록...나이가 들수록... 좋은 영화다. 현실속의 사랑이..\n",
      "개인적으로, 굉장한 걸작이란 생각이 든다. 여자가 강간을 당했다고 진술한 이유에 대해 논란이 많은데, '문화충격'으로 인한 심리적 여파와 영국인들의 텃세, 강압에 의해 어쩔 수 없이 거짓말한거라고 생각한다. 어찌되었든 최고의 걸작 중 하나..\n",
      "영화를 보면서 모든 화장을 마친 완벽한 여자의 모습과 화장을 지운 여자의 모습을 보는 것 같았다. 그만큼 반전의 느낌이 정말 강했다. 완벽하다고만 생각했는데 생각지도 못한 반전에 놀랐고 그 반전에 담겨있는 내용과 그 내용 풀이가 정말 좋았다.\n",
      "배우 이민호와 김희선의 어울리지 않을것 같은 어울림이 묘한 매력으로 다가오는 신의 ^^ 타임스립드라마의 최고봉이라 할 수 있답니다. 잔잔하게 애잔한 신의의 매력으로 풍덩 빠져보심이 어떨런지 ^^ 내인생 최고의 드라마였습니다. 적극 추천합니다.\n",
      "햇살님 평보고 너무 어이없어서 로그인하네요.역겨우면 영화를 보지 말지 그러셨어요.? 아니 애초부터 동성애에 대해 편견을 가지고 있는 분이라면 차라리 영화보지말지 굳이 감상평까지 친절하게 남겨주시네요ㅋ입장바꿔생각해봐요이렇게까지욕먹을껀아니라생각함\n",
      "사람들 절반이, 잘못알고있는데ㅋㅋ 진화촉진제 맞은 인간들이 바로 돌연변이 된게 아니라... 진화촉진제 맞은 인간들이ㅡ 후손남기고 극한환경에ㅡ 맞게끔 900년걸쳐서 진화한건데;;; 전자로 생각하면 진짜 평점 낮을수밖에ㅋ기자/평론가들 태반일거임ㅋ\n",
      "아시아권을넘어 세계적 예인(藝人)으로 살다간 \"그\" 가 가고 난 후에도 지금까지 난 그를 동시대 사람으로 늘 그리워하기에 혹시 내가 그의 흔적 무엇인가를 놓쳤을까봐 찾아보고 또 찾아본다. 그리고 지금 놓쳤던 그의 흔적 유성어를 지금 보고있다.\n",
      "이 영화 재미있게 본 분들은 이 영화 제작기 다큐인 \" Hearts of Darkness : A Filmmaker's Apocalypse\" 라는 다큐를 보세요. 또 다른 재미를 느끼실 수 있을 겁니다. 한글자막도 있으니 검색해서 찾아 보시길.\n",
      "다양성을 인정하지 못한다면, 이 불쾌한 영화가 싫을 수도 있다. 하지만 당신이 이 영화 속 인물들 때문에 역겨움을 느꼈다면, 아마 제작진의 의도는 거의 성공적으로 당신에게 먹힌것 일 거라고 생각한다.. 이 영화, 블랙코미디 영화라고 써있던데.\n",
      "단순히 겉모양만 흉내낸 것이 아닌 진짜 성찰이 있는 캐릭터들이 마치 톱니바퀴처럼 완벽하게 맞아 돌아간다. 다른 영화를 볼 때, '과연 내가 이런 영화를 만들 수 있을까?' 라는 생각을 하게 되는데 이 영화는 감히 그런 발상조차 할 수 없었다.\n",
      "님을 생각하면 너무 가슴 아프다... 일년 후 박사가 다시 왔을때... 님이 기뻐하며 안기는 그 모습만 생각하면 가슴이 아파 미치겠다...그리곤 다시 오지 않았지...인간의 잔인함... 님을 생각하면 가슴아프고...미안하고... 너무괴롭다..\n",
      "마지막까지 로맨틱한 사랑을 꿈꾸는 젊은 청춘들..허나 나같은 청춘의 마지막 기로에서도 아직까지 영원불멸 로맨틱을 꿈꾼다.. 이 영화는 점점 현실이 되어가서 실망을 안겨줄것 같다가도 그러나 영원불멸한 사랑은 꼭 존재한다는것을 가르쳐주었다 : )\n",
      "도심속에 꽉찬 머리속을 비우는 느낌이 좋다대사도 그리 많지 않고 잔잔하면서 서정적인 풍광작은집 외벽 이곳 저곳 벗겨진 페인트가 세월의 자연스러움을 보여준다이국적이지만 동양적 시각으로 앵글에 담겨진 하와이가너무나 아름답게 내눈을 편안하게 해준다\n",
      "사운드며 조승우의 보컬이 너무 좋았다.하지만 가장 좋았던겄은 별로 좋아하지 않았던신민아~♡그녀의 인생연기. 화면이(감독이 암흑기를 표현했겠지만)더 아름다웠을듯.좋아하는 감독님이 추억의 가요로 리머이크를 잘 해준다면 오백만 이상 자신해요~^^)\n"
     ]
    }
   ],
   "source": [
    "def check_sentence_with_length(raw, length):\n",
    "    count = 0\n",
    "    \n",
    "    for sen in raw:\n",
    "        if len(sen) == length:\n",
    "            print(sen)\n",
    "            count += 1\n",
    "            if count > 100: return \n",
    "\n",
    "check_sentence_with_length(naver_review, 135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "surgical-instrumentation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier Index: 2\n",
      "Outlier Index: 3\n",
      "Outlier Index: 4\n",
      "Outlier Index: 5\n",
      "Outlier Index: 6\n",
      "Outlier Index: 7\n",
      "Outlier Index: 8\n",
      "Outlier Index: 9\n",
      "Outlier Index: 10\n",
      "Outlier Index: 11\n",
      "Outlier Index: 12\n",
      "Outlier Index: 13\n",
      "Outlier Index: 14\n",
      "Outlier Index: 15\n",
      "Outlier Index: 16\n",
      "Outlier Index: 17\n",
      "Outlier Index: 18\n",
      "Outlier Index: 19\n",
      "Outlier Index: 20\n",
      "Outlier Index: 21\n",
      "Outlier Index: 22\n",
      "Outlier Index: 23\n",
      "Outlier Index: 24\n",
      "Outlier Index: 25\n",
      "Outlier Index: 26\n",
      "Outlier Index: 27\n",
      "Outlier Index: 28\n",
      "Outlier Index: 29\n",
      "Outlier Index: 30\n",
      "Outlier Index: 31\n",
      "Outlier Index: 32\n",
      "Outlier Index: 33\n",
      "Outlier Index: 34\n",
      "Outlier Index: 35\n",
      "Outlier Index: 36\n",
      "Outlier Index: 37\n",
      "Outlier Index: 38\n",
      "Outlier Index: 39\n",
      "Outlier Index: 40\n",
      "Outlier Index: 41\n",
      "Outlier Index: 42\n",
      "Outlier Index: 43\n",
      "Outlier Index: 44\n",
      "Outlier Index: 45\n",
      "Outlier Index: 46\n",
      "Outlier Index: 47\n",
      "Outlier Index: 48\n",
      "Outlier Index: 49\n",
      "Outlier Index: 50\n",
      "Outlier Index: 51\n",
      "Outlier Index: 52\n",
      "Outlier Index: 53\n",
      "Outlier Index: 54\n",
      "Outlier Index: 55\n",
      "Outlier Index: 56\n",
      "Outlier Index: 57\n",
      "Outlier Index: 58\n",
      "Outlier Index: 59\n",
      "Outlier Index: 60\n",
      "Outlier Index: 61\n",
      "Outlier Index: 62\n",
      "Outlier Index: 63\n",
      "Outlier Index: 64\n",
      "Outlier Index: 65\n",
      "Outlier Index: 66\n",
      "Outlier Index: 67\n",
      "Outlier Index: 68\n",
      "Outlier Index: 69\n",
      "Outlier Index: 70\n",
      "Outlier Index: 71\n",
      "Outlier Index: 72\n",
      "Outlier Index: 73\n",
      "Outlier Index: 74\n",
      "Outlier Index: 75\n",
      "Outlier Index: 76\n",
      "Outlier Index: 77\n",
      "Outlier Index: 78\n",
      "Outlier Index: 79\n",
      "Outlier Index: 80\n",
      "Outlier Index: 81\n",
      "Outlier Index: 82\n",
      "Outlier Index: 83\n",
      "Outlier Index: 84\n",
      "Outlier Index: 85\n",
      "Outlier Index: 86\n",
      "Outlier Index: 87\n",
      "Outlier Index: 88\n",
      "Outlier Index: 89\n",
      "Outlier Index: 90\n",
      "Outlier Index: 91\n",
      "Outlier Index: 92\n",
      "Outlier Index: 93\n",
      "Outlier Index: 94\n",
      "Outlier Index: 95\n",
      "Outlier Index: 96\n",
      "Outlier Index: 97\n",
      "Outlier Index: 98\n",
      "Outlier Index: 99\n",
      "Outlier Index: 100\n",
      "Outlier Index: 101\n",
      "Outlier Index: 102\n",
      "Outlier Index: 103\n",
      "Outlier Index: 104\n",
      "Outlier Index: 105\n",
      "Outlier Index: 106\n",
      "Outlier Index: 107\n",
      "Outlier Index: 108\n",
      "Outlier Index: 109\n",
      "Outlier Index: 110\n",
      "Outlier Index: 111\n",
      "Outlier Index: 112\n",
      "Outlier Index: 113\n",
      "Outlier Index: 114\n",
      "Outlier Index: 115\n",
      "Outlier Index: 116\n",
      "Outlier Index: 117\n",
      "Outlier Index: 118\n",
      "Outlier Index: 119\n",
      "Outlier Index: 120\n",
      "Outlier Index: 121\n",
      "Outlier Index: 122\n",
      "Outlier Index: 123\n",
      "Outlier Index: 124\n",
      "Outlier Index: 125\n",
      "Outlier Index: 126\n",
      "Outlier Index: 127\n",
      "Outlier Index: 128\n",
      "Outlier Index: 129\n",
      "Outlier Index: 130\n",
      "Outlier Index: 131\n",
      "Outlier Index: 132\n",
      "Outlier Index: 133\n",
      "Outlier Index: 134\n",
      "Outlier Index: 135\n",
      "Outlier Index: 136\n",
      "Outlier Index: 137\n",
      "Outlier Index: 138\n",
      "Outlier Index: 139\n",
      "Outlier Index: 140\n"
     ]
    }
   ],
   "source": [
    "# sentence_length[문장 길이] = 갯수 \n",
    "# idx = 문장길이 , _sum = 해당 문장 길이인 문장의 개수 \n",
    "\n",
    "for idx, _sum in enumerate(sentence_length):\n",
    "    # 문장의 수가 135 초과하는 문장 길이를 추출합니다.\n",
    "    if _sum > 135:\n",
    "        print(\"Outlier Index:\", idx+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-spectacular",
   "metadata": {},
   "source": [
    "**문장 길이 10 이하의 문장을 확인해봅니다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "controlling-tumor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "굿\n",
      "핡\n",
      "휴\n",
      "시\n",
      "ㅋ\n",
      "ㅇ\n",
      "‥\n",
      "O\n",
      "갑\n",
      "ㅎ\n",
      ".\n",
      "올\n",
      "헷\n",
      "g\n",
      "♥\n",
      "짱\n",
      "ㅆ\n",
      "굳\n",
      "잼\n",
      "ㅁ\n",
      "?\n",
      "애\n",
      "흠\n",
      "!\n",
      "찜\n",
      "b\n",
      ",\n",
      "1\n",
      "9\n",
      "♬\n",
      "ㅗ\n",
      "ㄳ\n",
      "ㄴ\n",
      "호\n",
      "a\n",
      "d\n",
      "f\n",
      "음\n",
      "헐\n",
      "캬\n",
      "린\n",
      "업\n",
      "乃\n",
      "ㅠ\n",
      ";\n",
      "·\n",
      "k\n",
      "움\n",
      "ㄱ\n",
      "쩜\n",
      "-\n",
      "군\n",
      "ㅉ\n",
      "훗\n",
      "z\n",
      "쨩\n",
      "뿌\n",
      "♡\n",
      "하\n",
      "h\n",
      "ㅍ\n",
      "꽉\n",
      "토\n",
      "귯\n",
      "아\n",
      "오\n",
      "ㅣ\n",
      "봐\n",
      "웅\n",
      "네\n",
      "ㅂ\n",
      "꿈\n",
      "헉\n",
      "와\n",
      "뻑\n",
      "걍\n",
      "헝\n",
      "우\n",
      "즛\n",
      "풉\n",
      "4\n",
      "쀍\n",
      "ㄹ\n",
      "삼\n",
      "쒯\n",
      "즐\n",
      "함\n",
      "0\n",
      "진\n",
      "악\n",
      "풋\n",
      "쩝\n",
      "욜\n",
      "ㄷ\n",
      "흐\n",
      "싫\n",
      "ㅜ\n",
      "잏\n",
      "허\n",
      "엿\n",
      "쉣\n"
     ]
    }
   ],
   "source": [
    "check_sentence_with_length(naver_review, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "skilled-waterproof",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "내 인생의 영화\n",
      "ㅎㅎㅎㅎㅎㅎㅎㅎ\n",
      "역시 최고였다.\n",
      "잘나갔지 콜트~\n",
      "나수윤의 발견!\n",
      "정말 멋진 영화\n",
      "매력넘치는 영화\n",
      "넘넘 재밌있었습\n",
      "훈훈한 영화~~\n",
      "참재밌게 봤다.\n",
      "무섭고 아쉽다.\n",
      "재미있었스니다.\n",
      "그냥 킬링타임용\n",
      "후회없는 영화!\n",
      "배창호 최고걸작\n",
      "행복한영호ㅓㅠㅠ\n",
      "재미 있습니다.\n",
      "모스크바가고싶다\n",
      "이건진짜명작이죠\n",
      "주옥 같은 영화\n",
      "재밌었어요ㅋㅋㅋ\n",
      "동양화같은 영화\n",
      "재밌는다큐였어요\n",
      "최고의영화...\n",
      "정말재밌어용..\n",
      "가슴 아파요..\n",
      "말이필요없지,,\n",
      "그냥 좋다 ㅎㅎ\n",
      "최고의 영화다.\n",
      "최고의순수의영화\n",
      "다시봐도 재밌다\n",
      "감동 적인 내용\n",
      "재밌어요~ ㅋㅋ\n",
      "멋지다 조문탁!\n",
      "재밌어요 ㅋㅋㅋ\n",
      "재미있고 참신함\n",
      "런닝맨완전재밌음\n",
      "난 재밌던데..\n",
      "오아오어ㅓ오ㅓ아\n",
      "재미있네요 !!\n",
      "즐겨보고있어요!\n",
      "즐거운 영화..\n",
      "정말 웃기네요.\n",
      "말이 필요 없다\n",
      "난해하다 외롭다\n",
      "재미있다~~~!\n",
      "꺄아~귀요미들~\n",
      "어쩜 절묘한지.\n",
      "멋있으세요 ^^\n",
      "엄청 웃낌 ㅋㅋ\n",
      "참 평화로워요.\n",
      "잠안올때 강추!\n",
      "좋다라는 말밖에\n",
      "웨스턴의 교과서\n",
      "단 하나의 사랑\n",
      "걍대박.....\n",
      "재밌어어용~~~\n",
      "끝까지 몰입이됨\n",
      "너무 재밌었어요\n",
      "아름다운 성장기\n",
      "전설에 동감..\n",
      "30번 넘게봤다\n",
      "떡밥계의 최고봉\n",
      "어떻게봐요이거?\n",
      "굿굿굿 굿이에요\n",
      "추억돋네요 ㅎㅎ\n",
      "걍 재미잇는영화\n",
      "재밌던데 뭘ㅎㅎ\n",
      "완전 재밋습니다\n",
      "좋은 영화네요.\n",
      "ㅋㅋㅋㅋㅋ재밌당\n",
      "느낌 좋은 영화\n",
      "감동ㅠㅠㅠㅠㅠㅠ\n",
      "대단한 영화였음\n",
      "좋다 진짜;;;\n",
      "재미있었는데..\n",
      "넘재밋다 ㅋㅋㅋ\n",
      "재밋어요 짱짱짱\n",
      "최고의우정이다.\n",
      "프랑스로 갈래~\n",
      "재미있어요 ㅋㅋ\n",
      "박지윤씨 이뻐요\n",
      "잔잔한웃음 ^^\n",
      "하지원 레전드임\n",
      "이젠 잘 살아라\n",
      "매력적인 무비;\n",
      "평점이 왜이러냐\n",
      "재미있게 보았다\n",
      "게리올드만 최고\n",
      "감동적입니다^^\n",
      "스토리탄탄 ㅠㅜ\n",
      "히트 재밋죠 ㅎ\n",
      "되게 묘함...\n",
      "마음에 듭니다.\n",
      "정말 완벽했다.\n",
      "솔까 재밌는데?\n",
      "말이 필요없음.\n",
      "신정환컴백하라~\n",
      "다시봐도 최고.\n",
      "까브리머싯씀ㅎㅎ\n",
      "샘이 돌아왔다.\n"
     ]
    }
   ],
   "source": [
    "check_sentence_with_length(naver_review, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "pleased-ultimate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쵝오\n",
      "최고\n",
      "좋아\n",
      "흐흐\n",
      "개쩜\n",
      "굳뜨\n",
      "좋다\n",
      "섬뜩\n",
      "♥♥\n",
      "ㅎㅎ\n",
      "대박\n",
      "잼슴\n",
      "굳굳\n",
      "10\n",
      "ㄹㄹ\n",
      "윤하\n",
      "유쾌\n",
      "긋~\n",
      "잼남\n",
      "박수\n",
      "수작\n",
      "굳!\n",
      "졸잼\n",
      "꿈.\n",
      "쏘우\n",
      "굿!\n",
      "명작\n",
      "대작\n",
      "잼네\n",
      "맞아\n",
      "ㅇㅇ\n",
      "완벽\n",
      "오우\n",
      "굿굿\n",
      "ㅠㅠ\n",
      "굿잡\n",
      "와우\n",
      "..\n",
      "좋네\n",
      "無言\n",
      "미투\n",
      "gg\n",
      "ㅋㅋ\n",
      "후훗\n",
      "걸작\n",
      "잼잼\n",
      "나두\n",
      "예뻐\n",
      "^^\n",
      "만점\n",
      "웃김\n",
      "오호\n",
      "설리\n",
      "좋너\n",
      "의읭\n",
      "감동\n",
      "원작\n",
      "구ㄷ\n",
      "하하\n",
      "좋음\n",
      "조앙\n",
      "멋져\n",
      "매력\n",
      "개박\n",
      "조음\n",
      "추천\n",
      "탁월\n",
      "조아\n",
      "쩔어\n",
      "감독\n",
      "가슴\n",
      "재밋\n",
      "잼씀\n",
      "진리\n",
      "붉다\n",
      "눈물\n",
      "오오\n",
      "9점\n",
      "zz\n",
      "잼따\n",
      "1등\n",
      "짱임\n",
      "홧팅\n",
      "쳐봐\n",
      "신고\n",
      "짱♥\n",
      "ㅡㅡ\n",
      "역시\n",
      "뻥임\n",
      "섹시\n",
      "명품\n",
      "우정\n",
      "짱~\n",
      "동참\n",
      "짱짱\n",
      "야한\n",
      "ㅊㅊ\n",
      "굿~\n",
      "대단\n",
      "반담\n",
      "만족\n"
     ]
    }
   ],
   "source": [
    "check_sentence_with_length(naver_review, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "judicial-greenhouse",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "재밌다\n",
      "가연세\n",
      "재밋다\n",
      "야마켄\n",
      "재밌음\n",
      "좋아요\n",
      "괜찮네\n",
      "화려함\n",
      "좋은데\n",
      "짱~~\n",
      "재밋음\n",
      "굿..\n",
      "킹왕짱\n",
      "재밌어\n",
      "까까~\n",
      "진짜다\n",
      "재밌당\n",
      "명작.\n",
      "잼있다\n",
      "재미다\n",
      "재미짐\n",
      "몽정기\n",
      "최고다\n",
      "각키♥\n",
      "수작.\n",
      "참재미\n",
      "채고야\n",
      "베리굳\n",
      "김은미\n",
      "굿!!\n",
      "갑이다\n",
      "구여움\n",
      "좋구나\n",
      "행~복\n",
      "10점\n",
      "ㅎ최고\n",
      "재밌군\n",
      "멋지당\n",
      "최고임\n",
      "똥파리\n",
      "잘봤음\n",
      "...\n",
      "조아요\n",
      "하하하\n",
      "굿굿굿\n",
      "훌륭함\n",
      "재미닷\n",
      "재밋당\n",
      "좋ㅎ음\n",
      "쩐다;\n",
      "ㅋㅋㅋ\n",
      "개코미\n",
      "화이팅\n",
      "잼네요\n",
      "귀여움\n",
      "으리!\n",
      "좋다.\n",
      "팬심♥\n",
      "볼만함\n",
      "감동적\n",
      "감동임\n",
      "감동~\n",
      "패닝짱\n",
      "목두기\n",
      "괜찬네\n",
      "재미씀\n",
      "좋네요\n",
      "참좋다\n",
      "동감.\n",
      "ㅋ재미\n",
      "재밋쪼\n",
      "한석규\n",
      "재밌긔\n",
      "웃긴데\n",
      "감동!\n",
      "ㅎㄷㄷ\n",
      "아프다\n",
      "대단함\n",
      "걸작.\n",
      "람보3\n",
      "명작!\n",
      "나의꿈\n",
      "잼겟따\n",
      "신선함\n",
      "갱호~\n",
      "재밌네\n",
      "대박!\n",
      "^-^\n",
      "연출력\n",
      "오ㅓㅏ\n",
      "재및음\n",
      "굿 ㅋ\n",
      "오호호\n",
      "괜찮음\n",
      "드라마\n",
      "zzz\n",
      "최고!\n",
      "감동함\n",
      "짱짱맨\n",
      "구구굿\n",
      "멋있다\n"
     ]
    }
   ],
   "source": [
    "check_sentence_with_length(naver_review, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "prescribed-poverty",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 194543\n",
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 142\n",
      "문장의 평균 길이: 36\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "cleaned_corpus = list(set(naver_review))  # set를 사용해서 중복을 제거합니다.\n",
    "print(\"Data Size:\", len(cleaned_corpus))\n",
    "\n",
    "for sen in cleaned_corpus:\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(cleaned_corpus))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in cleaned_corpus:   # 중복이 제거된 코퍼스 기준\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-tokyo",
   "metadata": {},
   "source": [
    "**\"문장길이 <= 100\"으로 처리해줍니다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "complicated-numbers",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182732 182732\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_len = 100\n",
    "# min_len = 0\n",
    "\n",
    "# 길이 조건에 맞는 문장만 선택합니다.\n",
    "filtered_corpus = [s for s in cleaned_corpus if (len(s) < max_len)]\n",
    "\n",
    "filtered_label = []\n",
    "for row, label in zip(naver_df['document'], naver_df['label']):\n",
    "    if (len(row) < max_len):\n",
    "        filtered_label.append(label) \n",
    "\n",
    "print(len(filtered_corpus), len(filtered_label))\n",
    "\n",
    "# 분포도를 다시 그려봅니다.\n",
    "sentence_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in filtered_corpus:\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "alive-moisture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 전 데이터 개수 : 194543\n",
      "전처리 후 데이터 개수 : 182732\n",
      "전처리 후 남은 데이터 양(%) 93.92884863500615\n"
     ]
    }
   ],
   "source": [
    "print('전처리 전 데이터 개수 :', len(naver_df))\n",
    "print('전처리 후 데이터 개수 :', len(filtered_corpus))\n",
    "print('전처리 후 남은 데이터 양(%)', (len(filtered_corpus)/len(naver_df))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize(corpus):  # corpus: Tokenized Sentence's List\n",
    "#     tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "#     tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "#     tensor = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "#     tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "#     return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-contest",
   "metadata": {},
   "source": [
    "## 2. SentencePiece 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "statewide-least",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import os\n",
    "temp_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp'\n",
    "\n",
    "vocab_size = 8000\n",
    "\n",
    "with open(temp_file, 'w') as f:\n",
    "    for row in filtered_corpus:   # 이전 스텝에서 정제했던 corpus를 활용합니다.\n",
    "        f.write(str(row) + '\\n')\n",
    "\n",
    "# vocab size=8000, model_type=unigram\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=kor_spm_unigram_8k --vocab_size={}'.format(temp_file, vocab_size)    \n",
    ")\n",
    "\n",
    "# 왜인지 오류가 나서 학습이 되지 않음 \n",
    "# vocab size=16000, model_type=unigram\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=kor_spm_uingram_k --vocab_size={}'.format(temp_file, 10000)    \n",
    ")\n",
    "\n",
    "# vocab size=8000, model_type=bpe\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=kor_spm_bpe_8k --model_type=bpe --vocab_size={}'.format(temp_file, vocab_size)    \n",
    ")\n",
    "\n",
    "# vocab size = 16000, model_type=bpe\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=kor_spm_bpe_16k --model_type=bpe --vocab_size={}'.format(temp_file, vocab_size*2)    \n",
    ")\n",
    "\n",
    "#위 Train에서  --model_type = 'unigram'이 디폴트 적용되어 있습니다. --model_type = 'bpe' 로 옵션을 주어 변경할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "transsexual-iraqi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 aiffel-dj26 aiffel-dj26 375116  4월 20 02:22 kor_spm_unigram_8k.model\n",
      "-rw-r--r-- 1 aiffel-dj26 aiffel-dj26 144574  4월 20 02:22 kor_spm_unigram_8k.vocab\n",
      "ls: cannot access 'kor_spm_unigram_16k*': No such file or directory\n",
      "-rw-r--r-- 1 aiffel-dj26 aiffel-dj26 370628  4월 20 02:22 kor_spm_bpe_8k.model\n",
      "-rw-r--r-- 1 aiffel-dj26 aiffel-dj26 115842  4월 20 02:22 kor_spm_bpe_8k.vocab\n",
      "-rw-r--r-- 1 aiffel-dj26 aiffel-dj26 523675  4월 20 02:22 kor_spm_bpe_16k.model\n",
      "-rw-r--r-- 1 aiffel-dj26 aiffel-dj26 258885  4월 20 02:22 kor_spm_bpe_16k.vocab\n"
     ]
    }
   ],
   "source": [
    "!ls -l kor_spm_unigram_8k*\n",
    "!ls -l kor_spm_unigram_16k*\n",
    "!ls -l kor_spm_bpe_8k*\n",
    "!ls -l kor_spm_bpe_16k*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-beatles",
   "metadata": {},
   "source": [
    "**학습된 subwords를 확인합니다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "nervous-glass",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>▁</td>\n",
       "      <td>-3.28356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.</td>\n",
       "      <td>-3.47793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>..</td>\n",
       "      <td>-4.30806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>이</td>\n",
       "      <td>-4.43464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>▁영화</td>\n",
       "      <td>-4.48224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>...</td>\n",
       "      <td>-4.54194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>가</td>\n",
       "      <td>-4.72835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1\n",
       "0  <unk>  0.00000\n",
       "1    <s>  0.00000\n",
       "2   </s>  0.00000\n",
       "3      ▁ -3.28356\n",
       "4      . -3.47793\n",
       "5     .. -4.30806\n",
       "6      이 -4.43464\n",
       "7    ▁영화 -4.48224\n",
       "8    ... -4.54194\n",
       "9      가 -4.72835"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list = pd.read_csv('kor_spm_unigram_8k.vocab', sep='\\t', header=None, quoting=csv.QUOTE_NONE)\n",
    "vocab_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ideal-invention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subword의 개수 : 8000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5744</th>\n",
       "      <td>섬</td>\n",
       "      <td>-10.55310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6408</th>\n",
       "      <td>▁뛰어넘는</td>\n",
       "      <td>-10.74440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6060</th>\n",
       "      <td>▁격투</td>\n",
       "      <td>-10.63700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>▁어느</td>\n",
       "      <td>-8.90350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>▁것</td>\n",
       "      <td>-7.15528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>▁주인공</td>\n",
       "      <td>-8.19596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3517</th>\n",
       "      <td>▁하네요</td>\n",
       "      <td>-9.93270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5708</th>\n",
       "      <td>▁뭐라고</td>\n",
       "      <td>-10.54340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4691</th>\n",
       "      <td>몸</td>\n",
       "      <td>-10.27950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4069</th>\n",
       "      <td>▁좋았지만</td>\n",
       "      <td>-10.10360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "5744      섬 -10.55310\n",
       "6408  ▁뛰어넘는 -10.74440\n",
       "6060    ▁격투 -10.63700\n",
       "1228    ▁어느  -8.90350\n",
       "151      ▁것  -7.15528\n",
       "555    ▁주인공  -8.19596\n",
       "3517   ▁하네요  -9.93270\n",
       "5708   ▁뭐라고 -10.54340\n",
       "4691      몸 -10.27950\n",
       "4069  ▁좋았지만 -10.10360"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('subword의 개수 :', len(vocab_list))\n",
    "vocab_list.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-replica",
   "metadata": {},
   "source": [
    "### SentencePiece 성능 비교평가\n",
    "- vocab size = 8k, 16k\n",
    "- model type = unigram, bpe\n",
    "\n",
    "\n",
    "- kor_spm_unigram_8k\n",
    "- kor_spm_unigram_16k\n",
    "- kor_spm_bpe_8k\n",
    "- kor_spm_bpe_16k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "coordinate-coordinate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_performance(model):\n",
    "    s = spm.SentencePieceProcessor()\n",
    "    s.Load(model)\n",
    "\n",
    "    # SentencePiece를 활용한 sentence -> encoding\n",
    "    tokensIDs = s.EncodeAsIds('아버지가방에들어가신다.')\n",
    "    print(tokensIDs)\n",
    "\n",
    "    # SentencePiece를 활용한 sentence -> encoded pieces\n",
    "    print(s.SampleEncodeAsPieces('아버지가방에들어가신다.',1, 0.0))\n",
    "\n",
    "    # SentencePiece를 활용한 encoding -> sentence 복원\n",
    "    print(s.DecodeIds(tokensIDs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bigger-vegetable",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kor_spm_unigram_8k\n",
      "[1509, 9, 406, 15, 1342, 9, 138, 17, 4]\n",
      "['▁아버지', '가', '방', '에', '들어', '가', '신', '다', '.']\n",
      "아버지가방에들어가신다.\n",
      "kor_spm_bpe_8k\n",
      "[5057, 912, 6550, 6283, 1469, 6279, 6385, 6273, 6271]\n",
      "['▁아버', '지가', '방', '에', '들어', '가', '신', '다', '.']\n",
      "아버지가방에들어가신다.\n",
      "kor_spm_bpe_16k\n",
      "[7880, 10978, 1469, 14279, 12313, 14271]\n",
      "['▁아버지가', '방에', '들어', '가', '신다', '.']\n",
      "아버지가방에들어가신다.\n"
     ]
    }
   ],
   "source": [
    "print('kor_spm_unigram_8k')\n",
    "test_performance(model='kor_spm_unigram_8k.model')\n",
    "\n",
    "# unigram은 오류가 나서 학습이 되지 않았다. \n",
    "# print('kor_spm_unigram_16k')\n",
    "# test_performance(model='kor_spm_unigram_16k.model')\n",
    "\n",
    "print('kor_spm_bpe_8k')\n",
    "test_performance(model='kor_spm_bpe_8k.model')\n",
    "\n",
    "print('kor_spm_bpe_16k')\n",
    "test_performance(model='kor_spm_bpe_16k.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insured-cartridge",
   "metadata": {},
   "source": [
    "**bpe, vocab size 16k로 설정한 모델이 '아버지가', '방에'를 구분하였다.**\n",
    "\n",
    "## 3. Tokenizer 함수 작성 \n",
    "- 훈련시킨 SentencePiece를 활용해 tokenizer역할을 하는 함수를 정의합니다. \n",
    "- 함수의 조건 \n",
    "    1. 매개변수로 토큰화된 문장의 list를 전달하는 대신 온전한 문장의 list 를 전달합니다.\n",
    "    2. 생성된 vocab 파일을 읽어와 \\{ \\<word> : \\<idx> } 형태를 가지는 word_index 사전과 { \\<idx> : \\<word>} 형태를 가지는 index_word 사전을 생성하고 함께 반환합니다.\n",
    "    3. 리턴값인 tensor는 앞의 함수와 동일하게 토큰화한 후 Encoding된 문장입니다. 바로 학습에 사용할 수 있게 Padding은 당연히 해야겠죠?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "coral-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_tokenize(s, corpus):\n",
    "\n",
    "    tensor = []\n",
    "\n",
    "    for sen in corpus:\n",
    "        tensor.append(s.EncodeAsIds(sen))\n",
    "\n",
    "    with open(\"./kor_spm_bpe_16k.vocab\", 'r') as f:\n",
    "        vocab = f.readlines()\n",
    "\n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "\n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split(\"\\t\")[0]\n",
    "\n",
    "        word_index.update({idx:word})\n",
    "        index_word.update({word:idx})\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=max_len)\n",
    "\n",
    "    return tensor, word_index, index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "functioning-westminster",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 558 3386   14 1379 2213    4    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [1580 2273  253  592    9    3   16 7937  688    8    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n"
     ]
    }
   ],
   "source": [
    "# sp_tokenize(s, corpus) 사용 예제\n",
    "\n",
    "s = spm.SentencePieceProcessor()\n",
    "# s.Load('kor_spm_bpe_16k.model')  # lstm 학습시 오류\n",
    "\n",
    "s.Load('kor_spm_unigram_8k.model') \n",
    "\n",
    "my_corpus = ['나는 밥을 먹었습니다.', '그러나 여전히 ㅠㅠ 배가 고픕니다...']\n",
    "tensor, word_index, index_word = sp_tokenize(s, my_corpus)\n",
    "print(tensor)\n",
    "# print(word_index)\n",
    "# print(index_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-cholesterol",
   "metadata": {},
   "source": [
    "## 4. lstm으로 감정분석 모델 학습 \n",
    "- SentencePiece 토크나이저가 적용된 모델을 학습 후 수렴하는 것을 확인합니다.\n",
    "- SentencePiece 토크나이저 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "clinical-outside",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor, word_index, index_word = sp_tokenize(s, filtered_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "romantic-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "filtered_label = np.array(filtered_label)\n",
    "x_train, x_test, y_train, y_test = train_test_split(tensor, filtered_label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "oriented-representative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146185 36547\n",
      "146185 36547\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), len(x_test))\n",
    "print(len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "responsible-relation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 512)               1460224   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,460,737\n",
      "Trainable params: 3,460,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000\n",
    "word_vector_dim = 200  \n",
    "\n",
    "model_LSTM = keras.Sequential()\n",
    "model_LSTM.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim)   \n",
    "              ) \n",
    "model_LSTM.add(keras.layers.LSTM(512))   \n",
    "model_LSTM.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model_LSTM.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-function",
   "metadata": {},
   "source": [
    "**bpe, vocab size 16k로 설정한 모델은 에러가 났다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "tender-longer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 146185 samples\n",
      "Epoch 1/10\n",
      "  1000/146185 [..............................] - ETA: 3:32"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument:  indices[751,1] = 14292 is not in [0, 10000)\n\t [[node sequential_3/embedding_1/embedding_lookup (defined at <ipython-input-93-dae0afa237b2>:12) ]]\n  (1) Invalid argument:  indices[751,1] = 14292 is not in [0, 10000)\n\t [[node sequential_3/embedding_1/embedding_lookup (defined at <ipython-input-93-dae0afa237b2>:12) ]]\n\t [[Adam/Adam/update/AssignSubVariableOp/_41]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_3817]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_3/embedding_1/embedding_lookup:\n sequential_3/embedding_1/embedding_lookup/2646 (defined at /home/aiffel-dj26/anaconda3/envs/aiffel/lib/python3.7/contextlib.py:112)\n\nInput Source operations connected to node sequential_3/embedding_1/embedding_lookup:\n sequential_3/embedding_1/embedding_lookup/2646 (defined at /home/aiffel-dj26/anaconda3/envs/aiffel/lib/python3.7/contextlib.py:112)\n\nFunction call stack:\ndistributed_function -> distributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-dae0afa237b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                     verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  indices[751,1] = 14292 is not in [0, 10000)\n\t [[node sequential_3/embedding_1/embedding_lookup (defined at <ipython-input-93-dae0afa237b2>:12) ]]\n  (1) Invalid argument:  indices[751,1] = 14292 is not in [0, 10000)\n\t [[node sequential_3/embedding_1/embedding_lookup (defined at <ipython-input-93-dae0afa237b2>:12) ]]\n\t [[Adam/Adam/update/AssignSubVariableOp/_41]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_3817]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_3/embedding_1/embedding_lookup:\n sequential_3/embedding_1/embedding_lookup/2646 (defined at /home/aiffel-dj26/anaconda3/envs/aiffel/lib/python3.7/contextlib.py:112)\n\nInput Source operations connected to node sequential_3/embedding_1/embedding_lookup:\n sequential_3/embedding_1/embedding_lookup/2646 (defined at /home/aiffel-dj26/anaconda3/envs/aiffel/lib/python3.7/contextlib.py:112)\n\nFunction call stack:\ndistributed_function -> distributed_function\n"
     ]
    }
   ],
   "source": [
    "model_LSTM.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=10\n",
    "batch_size=1000\n",
    "\n",
    "history_LSTM = model_LSTM.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "unlikely-defendant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 146185 samples\n",
      "Epoch 1/10\n",
      "146185/146185 [==============================] - 41s 284us/sample - loss: 0.6933 - accuracy: 0.5024\n",
      "Epoch 2/10\n",
      "146185/146185 [==============================] - 39s 270us/sample - loss: 0.6932 - accuracy: 0.5040\n",
      "Epoch 3/10\n",
      "146185/146185 [==============================] - 40s 270us/sample - loss: 0.6932 - accuracy: 0.5028\n",
      "Epoch 4/10\n",
      "146185/146185 [==============================] - 40s 270us/sample - loss: 0.6931 - accuracy: 0.5029\n",
      "Epoch 5/10\n",
      "146185/146185 [==============================] - 40s 271us/sample - loss: 0.6931 - accuracy: 0.5030\n",
      "Epoch 6/10\n",
      "146185/146185 [==============================] - 40s 271us/sample - loss: 0.6931 - accuracy: 0.5041\n",
      "Epoch 7/10\n",
      "146185/146185 [==============================] - 40s 270us/sample - loss: 0.6931 - accuracy: 0.5041\n",
      "Epoch 8/10\n",
      "146185/146185 [==============================] - 40s 272us/sample - loss: 0.6931 - accuracy: 0.5041\n",
      "Epoch 9/10\n",
      "146185/146185 [==============================] - 40s 271us/sample - loss: 0.6931 - accuracy: 0.5041\n",
      "Epoch 10/10\n",
      "146185/146185 [==============================] - 41s 283us/sample - loss: 0.6931 - accuracy: 0.5041\n"
     ]
    }
   ],
   "source": [
    "model_LSTM.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=10\n",
    "batch_size=1000\n",
    "\n",
    "history_LSTM = model_LSTM.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-conviction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "major-williams",
   "metadata": {},
   "source": [
    "# 루브릭 평가\n",
    "---\n",
    "1. **SentencePiece를 이용하여 모델을 만들기까지의 과정이 정상적으로 진행되었는가?**   \n",
    "\n",
    "    - 코퍼스 분석, 전처리, SentencePiece 적용, 토크나이저 구현 및 동작이 빠짐없이 진행되었는가?\n",
    "\n",
    "\n",
    "2. **SentencePiece를 통해 만든 Tokenizer가 자연어처리 모델과 결합하여 동작하는가?**\n",
    "\n",
    "    - SentencePiece 토크나이저가 적용된 Text Classifier 모델이 정상적으로 수렴하여 80% 이상의 test accuracy가 확인되었다.\n",
    "     \n",
    "     \n",
    "3. **SentencePiece의 성능을 다각도로 비교분석하였는가?** \n",
    "\n",
    "    - SentencePiece 토크나이저를 활용했을 때의 성능을 다른 토크나이저 혹은 SentencePiece의 다른 옵션의 경우와 비교하여 분석을 체계적으로 진행하였다.\n",
    "\n",
    "    \n",
    "    \n",
    "# 회고\n",
    "---\n",
    "\n",
    "## 다짐"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
