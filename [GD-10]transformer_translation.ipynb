{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "polyphonic-irrigation",
   "metadata": {},
   "source": [
    "# [Going Deeper NLP 10] 한영 번역기 만들기\n",
    "attention을 기반으로 한 seq2seq모델로 한영 번역기를 생성하는 프로젝트  \n",
    "\n",
    "---\n",
    "\n",
    "## 프로젝트 목표\n",
    "---\n",
    "- seq2seq 모델을 구현하며 이해한다.\n",
    "- 기대 효과를 충족하는 모델을 구현한다.\n",
    "\n",
    "## 프로젝트 설명\n",
    "---\n",
    "1. 데이터 다운로드 : [링크](https://github.com/jungyeul/korean-parallel-corpora/blob/master/korean-english-news-v1/korean-english-park.train.tar.gz)\n",
    "2. 데이터 정제 \n",
    "    - 중복, 결측치 제거\n",
    "    - 한글 데이터 처리\n",
    "    - 토큰 추가 \n",
    "3. 데이터 토큰화 \n",
    "4. 모델 설계 \n",
    "5. 훈련 및 attention map 시각화 \n",
    "\n",
    "    \n",
    "## 0. Import module, library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-recruitment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-reset",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-aging",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-pierce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "breathing-indication",
   "metadata": {},
   "source": [
    "# 루브릭 평가\n",
    "---\n",
    "1. **번역기 모델 학습에 필요한 텍스트 데이터 전처리가 잘 이루어졌다.**   \n",
    "    - 데이터 정제, SentencePiece를 활용한 토큰화 및 데이터셋 구축의 과정이 지시대로 진행되었다.\n",
    "\n",
    "\n",
    "2. **Transformer 번역기 모델이 정상적으로 구동된다.**\n",
    "\n",
    "    - Transformer 모델의 학습과 추론 과정이 정상적으로 진행되어, 한-영 번역기능이 정상 동작한다.\n",
    "\n",
    "\n",
    "3. **테스트 결과 의미가 통하는 수준의 번역문이 생성되었다.** \n",
    " \n",
    "     - 제시된 문장에 대한 그럴듯한 영어 번역문이 생성되며, 시각화된 Attention Map으로 결과를 뒷받침한다.\n",
    "\n",
    "\n",
    "    \n",
    "# 회고\n",
    "---\n",
    "## 어려웠던 부분 \n",
    "- 데이터셋 자체의 신뢰도가 낮았다. \n",
    "\n",
    "## 알아낸 점 혹은 모호한 부분 \n",
    "- mecab으로 형태소 단위로 분해하는 것과 토큰화하는 것을 다르게 하는 것에 대해 배울 수 있었다. \n",
    "- 데이터셋을 검증할 수 있는 방법에 대해 알아봐야겠다. 9만 여개의 데이터를 전부 확인할 수 없었다. \n",
    "- attention 메커니즘에 대해 직접 구성할 수 있어서 좋았다. \n",
    "\n",
    "## 느낀 점 \n",
    "- transformer로 학습시키면 더 성능이 좋을 것이라고 예상된다. 다음 프로젝트가 기대된다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
