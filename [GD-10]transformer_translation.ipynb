{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "engaging-psychology",
   "metadata": {},
   "source": [
    "# [Going Deeper NLP 10] 더 멋진 번역기 만들기\n",
    "transformer 모델을 이용해 한영 번역기를 만든다.\n",
    "\n",
    "---\n",
    "\n",
    "## 프로젝트 목표\n",
    "---\n",
    "- transformer 모델을 이해, 구현한다. \n",
    "\n",
    "## 프로젝트 설명\n",
    "---\n",
    "1. 데이터 다운로드 : [링크](https://github.com/jungyeul/korean-parallel-corpora/blob/master/korean-english-news-v1/korean-english-park.train.tar.gz)\n",
    "2. 데이터 정제 \n",
    "    - 중복, 결측치 제거\n",
    "    - 한글 데이터 처리\n",
    "    - 영어 소문자 변환\n",
    "    - 토큰 추가 \n",
    "3. 데이터 토큰화 \n",
    "4. 모델 설계 \n",
    "5. 훈련 및 평가 \n",
    "\n",
    "    \n",
    "## 0. Import module, library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unsigned-magnet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한글 적용 완료\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "%config InlineBackend.figure_format = 'retina'\n",
    " \n",
    "import matplotlib.font_manager as fm\n",
    "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "mpl.font_manager._rebuild()\n",
    "\n",
    "print(\"한글 적용 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "secure-negotiation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0-rc2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import random\n",
    "\n",
    "import seaborn # Attention 시각화를 위해 필요!\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-yugoslavia",
   "metadata": {},
   "source": [
    "## 1. 데이터 정제 및 토큰화\n",
    "- 데이터 중복 제거 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fabulous-interest",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/transformer/data'\n",
    "kor_path = data_dir+\"/korean-english-park.train.ko\"\n",
    "eng_path = data_dir+\"/korean-english-park.train.en\"\n",
    "\n",
    "def clean_corpus(kor_path, eng_path):\n",
    "    with open(kor_path, \"r\") as f: \n",
    "        kor = f.read().splitlines()\n",
    "    with open(eng_path, \"r\") as f: \n",
    "        eng = f.read().splitlines()\n",
    "    assert len(kor) == len(eng)\n",
    "\n",
    "    raw = zip(kor, eng)\n",
    "    cleaned_corpus = set(raw)\n",
    "\n",
    "    return cleaned_corpus\n",
    "\n",
    "cleaned_corpus = clean_corpus(kor_path, eng_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "young-liberty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78968 78968\n"
     ]
    }
   ],
   "source": [
    "kor_corpus, eng_corpus = zip(*cleaned_corpus)\n",
    "print(len(kor_corpus), len(eng_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-central",
   "metadata": {},
   "source": [
    "- 데이터 정제\n",
    "    1. 영문 소문자 변환\n",
    "    2. 알파벳, 문장부호, 한글 제외는 제거\n",
    "    3. 문장부호 양 옆에 공백 추가 \n",
    "    4. 불필요한 공백 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "swiss-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    \n",
    "    sentence = sentence.lower().strip()\n",
    "\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!가-힣ㄱ-ㅎㅏ-ㅣ]+\", \" \", sentence)\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hollywood-capital",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "korean data size: 78968\n",
      "english data size: 78968\n",
      "Korean: 오바마 정권인수팀 부시 행정명령 전면 재검토 중\n",
      "English: obama team reviewing virtually every agency aide says\n"
     ]
    }
   ],
   "source": [
    "enc_corpus = []\n",
    "dec_corpus = []\n",
    "\n",
    "for kor, eng in zip(kor_corpus, eng_corpus):\n",
    "    temp_kor = preprocess_sentence(kor)\n",
    "    temp_eng = preprocess_sentence(eng)\n",
    "\n",
    "    enc_corpus.append(temp_kor)\n",
    "    dec_corpus.append(temp_eng)\n",
    "    \n",
    "print('korean data size:', len(enc_corpus))\n",
    "print('english data size:', len(dec_corpus))\n",
    "print(\"Korean:\", enc_corpus[500])   \n",
    "print(\"English:\", dec_corpus[500])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-enclosure",
   "metadata": {},
   "source": [
    "- 데이터 토큰화\n",
    "    - Sentencepiece활용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-grenada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-recording",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-integration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-emphasis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-feature",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-desperate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-sequence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-admission",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-dynamics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-click",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "mobile-restriction",
   "metadata": {},
   "source": [
    "# 루브릭 평가\n",
    "---\n",
    "1. **번역기 모델 학습에 필요한 텍스트 데이터 전처리가 잘 이루어졌다.**   \n",
    "    - 데이터 정제, SentencePiece를 활용한 토큰화 및 데이터셋 구축의 과정이 지시대로 진행되었다.\n",
    "\n",
    "\n",
    "2. **Transformer 번역기 모델이 정상적으로 구동된다.**\n",
    "\n",
    "    - Transformer 모델의 학습과 추론 과정이 정상적으로 진행되어, 한-영 번역기능이 정상 동작한다.\n",
    "\n",
    "\n",
    "3. **테스트 결과 의미가 통하는 수준의 번역문이 생성되었다.** \n",
    " \n",
    "     - 제시된 문장에 대한 그럴듯한 영어 번역문이 생성되며, 시각화된 Attention Map으로 결과를 뒷받침한다.\n",
    "\n",
    "\n",
    "    \n",
    "# 회고\n",
    "---\n",
    "## 어려웠던 부분 \n",
    "- \n",
    "\n",
    "## 알아낸 점 혹은 모호한 부분 \n",
    "- \n",
    "\n",
    "## 느낀 점 \n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
