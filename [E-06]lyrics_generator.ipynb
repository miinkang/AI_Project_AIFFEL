{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "helpful-glory",
   "metadata": {},
   "source": [
    "# [Exploration 06] 멋진 작사가 만들기\n",
    "## 01. download data\n",
    "- 학습할 텍스트 데이터를 다운로드합니다.\n",
    "- 해당 프로젝트에서는 작사가를 만들기 위해 가사 데이터를 다운로드합니다. \n",
    "\n",
    "## 02. load data \n",
    "- glob 모듈을 사용해 파일을 읽습니다. \n",
    "- 문장 단위로 끊어서 corpus(말뭉치 데이터)를 저장합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "subjective-advocate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " ['I. LIFE.', '', '']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "raw_corpus = []\n",
    "\n",
    "for txt_file in txt_list:\n",
    "    # with구문으로 txt_list에 있는 txt_file 하나하나를 열어줍니다.\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        # line을 기준으로 문장단위로 끊어서 raw변수에 넣어줍니다.\n",
    "        raw = f.read().splitlines()\n",
    "        # 리스트로 생성된 raw는 append가 아닌 extend로 raw_corpus에 더합니다.\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-wesley",
   "metadata": {},
   "source": [
    "## 03. preprocess data \n",
    "- 적절한 문장의 길이를 구해서, padding을 하거나 잘라줍니다.\n",
    "- tf.keras.preprocessing.text.Tokenizer 패키지를 이용해 정제된 데이터를 토큰화합니다.\n",
    "- 토큰을 모아 사전을 만들고, 숫자로 변환해줍니다.\n",
    "- 이때 숫자로 변환된 데이터(해당 프로젝트에서는 노래 가사)를 텐서(tensor)라고 합니다.\n",
    "- 해당 프로젝트에서는 한 문장에 토큰 15개를 권장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "occupied-finding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I. LIFE.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'I.',\n",
       " '',\n",
       " 'SUCCESS.',\n",
       " '',\n",
       " '[Published in \"A Masque of Poets\"',\n",
       " 'at the request of \"H.H.,\" the author\\'s',\n",
       " 'fellow-townswoman and friend.]',\n",
       " '',\n",
       " 'Success is counted sweetest']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_corpus[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "swedish-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()      \n",
    "  \n",
    "    # 불필요한 특수기호, 공백 등의 패턴을 지우고 공백으로 단어를 토큰화할 수 있도록 정제합니다\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)    # 패턴의 특수문자 -> 공백\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)           # 공백 패턴 -> 스페이스 1개\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)  # a-zA-Z?.!,¿ 패턴을 제외한 모든 문자(공백문자까지도) -> 스페이스 1개\n",
    "\n",
    "    sentence = sentence.strip()                           \n",
    "    sentence = '<start> ' + sentence + ' <end>'           # 문장 앞뒤로 <start>와 <end>를 단어처럼 붙여 줍니다\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "grave-shuttle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> published in a masque of poets <end>'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = '[Published in \"A Masque of Poets\"'\n",
    "sentence_1 = preprocess_sentence(sentence)\n",
    "sentence_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eleven-rocket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175986"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    if len(sentence) == 0:\n",
    "        continue\n",
    "\n",
    "    corpus.append(preprocess_sentence(sentence))\n",
    "\n",
    "corpus[:100]\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "northern-copying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2    5   20 ...    0    0    0]\n",
      " [   2    5   20 ...    0    0    0]\n",
      " [   2 2762   20 ...    0    0    0]\n",
      " ...\n",
      " [   2    7 1021 ...    0    0    0]\n",
      " [   2   30   31 ...    0    0    0]\n",
      " [   2   50    5 ...    0    0    0]] \n",
      " <keras_preprocessing.text.Tokenizer object at 0x7fab37ac2890>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(175986, 175986)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def tokenize(corpus):\n",
    "    # Tokenizer 패키지를 생성합니다.\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000,  # 단어장의 크기를 설정합니다. (권장 12,000 이상)      \n",
    "        filters=' ',      # 별도의 전처리 로직           \n",
    "        oov_token=\"<unk>\" # out-of-vocabulary, 사전에 없었던 단어            \n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)   # corpus로부터 Tokenizer가 사전을 구축하는 함수       \n",
    "\n",
    "    # 이후 tokenizer를 활용하여 모델에 입력할 데이터셋을 구축하게 됩니다.\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   # tokenizer는 구축한 사전으로부터 corpus를 해석해 Tensor로 변환합니다.\n",
    "\n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞추기 위한 padding  메소드를 제공합니다.   \n",
    "    # maxlen는 시퀀스 길이를 뜻합니다. 지정하지 않을 때는 None이 디폴트값입니다.       \n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, maxlen=50, padding='post')  \n",
    "\n",
    "    print(tensor,'\\n', tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)\n",
    "\n",
    "len(tensor), len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-estimate",
   "metadata": {},
   "source": [
    "tokenizer를 통해 토큰화한 tensor data를 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "positive-improvement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    2     5    20   102    20     3     0     0     0     0     0     0]\n",
      " [    2     5    20     3     0     0     0     0     0     0     0     0]\n",
      " [    2  2762    20     3     0     0     0     0     0     0     0     0]\n",
      " [    2  9571    14     9     1    19  7664     3     0     0     0     0]\n",
      " [    2    71     6  5344    19  1902    20  1902    20     4     6  7665]\n",
      " [    2  4379     1     8   308    20     3     0     0     0     0     0]\n",
      " [    2  2762    26  5044  2353     3     0     0     0     0     0     0]\n",
      " [    2   122   423    97  2267  1114  7666    20     3     0     0     0]\n",
      " [    2    10  9572     9  8552     3     0     0     0     0     0     0]\n",
      " [    2 11343     1    90    20     3     0     0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "print(tensor[:10, :12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-magic",
   "metadata": {},
   "source": [
    "모든 데이터가 2로 시작하고, 3으로 끝나는 것을 알 수 있습니다.    \n",
    "2와 3이 무엇을 뜻하는지 확인해보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "challenging-possible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : ,\n",
      "5 : i\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n"
     ]
    }
   ],
   "source": [
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 10: \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-lloyd",
   "metadata": {},
   "source": [
    "인덱스 2, 3은 \\<start>와 \\<end>였습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-attitude",
   "metadata": {},
   "source": [
    "## 04. split data\n",
    "- 학습할 데이터(x-data)와 정답 데이터(y-data)를 만듭니다.\n",
    "- Dataset객체를 생성합니다.\n",
    "- 데이터 셋을 train, test로 분할합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bigger-hayes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2   5  20 102  20   3   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "[  5  20 102  20   3   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "# 소스 문장 : tensor에서 마지막 토큰(<end> or <pad>)을 제외합니다. : <pad>일 가능성이 높습니다. \n",
    "src_input = tensor[:, :-1]  \n",
    "# 타겟 문장 : tensor에서 <start>를 잘라내 생성합니다.\n",
    "tgt_input = tensor[:, 1:]   \n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "large-current",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (140788, 49)\n",
      "Target Train: (140788, 49)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "enc_train, enc_val, dec_train, enc_val = train_test_split(src_input, tgt_input, test_size=0.2)\n",
    "\n",
    "print(\"Source Train:\", enc_train.shape)\n",
    "print(\"Target Train:\", dec_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "applied-guitar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 49), (256, 49)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "print(BUFFER_SIZE)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1  # 사전에 포함되지 않은 0:<pad>를 더해줍니다.\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "approximate-artist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 49), (256, 49)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "print(BUFFER_SIZE)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1  # 사전에 포함되지 않은 0:<pad>를 더해줍니다.\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((enc_val, enc_val)).shuffle(BUFFER_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-requirement",
   "metadata": {},
   "source": [
    "## 05. build model\n",
    "- 10 Epoch 내에 val_loss 값을 2.2 수준으로 줄일 수 있는 모델을 설계합니다. \n",
    "- 모델은 embedding layer, lstm layer, dense layer로 구성되어있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "tired-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        # return_sequences = 마지막 출력을 반환할지에 대한 여부 \n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "model = TextGenerator(VOCAB_SIZE, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-spanking",
   "metadata": {},
   "source": [
    "input을 모델에 넣으면 input shape가 지정되면서 자동으로 model.build()가 호출됩니다.   \n",
    "train_dataset의 데이터 하나만 모델에 넣어 테스트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "historic-minister",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 49, 12001), dtype=float32, numpy=\n",
       "array([[[ 1.25659644e-04,  1.05638996e-04,  1.64925543e-04, ...,\n",
       "         -9.08747534e-05,  1.95486442e-04,  9.62465419e-05],\n",
       "        [ 6.74160692e-05,  3.34635697e-04,  4.17240284e-04, ...,\n",
       "         -1.41740922e-04,  1.35734415e-04,  7.56428199e-05],\n",
       "        [-1.62594461e-05,  5.68517891e-04,  5.85885020e-04, ...,\n",
       "         -1.57546237e-05, -1.28882966e-05,  1.12312067e-04],\n",
       "        ...,\n",
       "        [ 1.78915379e-03, -8.64550588e-04, -8.55218095e-04, ...,\n",
       "         -3.76240886e-03,  1.84219016e-03, -3.35137651e-04],\n",
       "        [ 1.78851315e-03, -8.64416361e-04, -8.55824037e-04, ...,\n",
       "         -3.76546080e-03,  1.84393895e-03, -3.36147088e-04],\n",
       "        [ 1.78802013e-03, -8.64222588e-04, -8.56327883e-04, ...,\n",
       "         -3.76801472e-03,  1.84550451e-03, -3.37014964e-04]],\n",
       "\n",
       "       [[ 1.25659644e-04,  1.05638996e-04,  1.64925543e-04, ...,\n",
       "         -9.08747534e-05,  1.95486442e-04,  9.62465419e-05],\n",
       "        [ 1.61236225e-04, -4.44814359e-05,  2.98853236e-04, ...,\n",
       "         -2.02183510e-04,  2.80576962e-04, -2.24859541e-04],\n",
       "        [-1.41719836e-04, -3.06222879e-04,  2.00732466e-04, ...,\n",
       "         -5.27296579e-05,  1.88124803e-04, -4.21099277e-04],\n",
       "        ...,\n",
       "        [ 1.80371327e-03, -8.44289432e-04, -8.38685199e-04, ...,\n",
       "         -3.70025146e-03,  1.79163448e-03, -3.03171371e-04],\n",
       "        [ 1.80083932e-03, -8.49467295e-04, -8.42141046e-04, ...,\n",
       "         -3.71325738e-03,  1.80022710e-03, -3.07723531e-04],\n",
       "        [ 1.79833604e-03, -8.53555801e-04, -8.44977272e-04, ...,\n",
       "         -3.72420391e-03,  1.80770399e-03, -3.11805838e-04]],\n",
       "\n",
       "       [[ 1.25659644e-04,  1.05638996e-04,  1.64925543e-04, ...,\n",
       "         -9.08747534e-05,  1.95486442e-04,  9.62465419e-05],\n",
       "        [ 1.94341366e-04,  3.98467600e-05,  4.03002370e-04, ...,\n",
       "         -7.39055904e-05,  7.81873532e-05,  4.58245340e-05],\n",
       "        [ 1.36462986e-04,  9.34420314e-06,  1.43618265e-04, ...,\n",
       "          1.42058580e-05, -6.94847449e-06, -1.78254650e-05],\n",
       "        ...,\n",
       "        [ 1.78577437e-03, -8.62522691e-04, -8.55596911e-04, ...,\n",
       "         -3.77103989e-03,  1.84734294e-03, -3.35071556e-04],\n",
       "        [ 1.78582745e-03, -8.62526183e-04, -8.56073108e-04, ...,\n",
       "         -3.77259566e-03,  1.84859172e-03, -3.36108962e-04],\n",
       "        [ 1.78589951e-03, -8.62480432e-04, -8.56484228e-04, ...,\n",
       "         -3.77389975e-03,  1.84969662e-03, -3.37002333e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.25659644e-04,  1.05638996e-04,  1.64925543e-04, ...,\n",
       "         -9.08747534e-05,  1.95486442e-04,  9.62465419e-05],\n",
       "        [ 2.60480505e-04,  2.39362053e-04,  3.53919691e-04, ...,\n",
       "         -2.48325741e-05,  1.97721631e-04, -1.47300234e-04],\n",
       "        [ 5.53121557e-04,  3.75316740e-04,  4.06167441e-04, ...,\n",
       "          9.22139880e-05,  1.61959542e-04, -2.34283580e-04],\n",
       "        ...,\n",
       "        [ 1.78795215e-03, -8.61268549e-04, -8.47806339e-04, ...,\n",
       "         -3.74511606e-03,  1.82823883e-03, -3.23863031e-04],\n",
       "        [ 1.78734132e-03, -8.62154702e-04, -8.49439646e-04, ...,\n",
       "         -3.75110935e-03,  1.83191011e-03, -3.26307578e-04],\n",
       "        [ 1.78685982e-03, -8.62749002e-04, -8.50826560e-04, ...,\n",
       "         -3.75611335e-03,  1.83511421e-03, -3.28444148e-04]],\n",
       "\n",
       "       [[ 1.25659644e-04,  1.05638996e-04,  1.64925543e-04, ...,\n",
       "         -9.08747534e-05,  1.95486442e-04,  9.62465419e-05],\n",
       "        [-1.04269267e-04, -1.36547305e-05,  7.15721690e-05, ...,\n",
       "          6.55515687e-05,  1.49476589e-04,  6.37892153e-05],\n",
       "        [-3.59752827e-04, -2.07010075e-04, -3.23732274e-05, ...,\n",
       "          1.38005722e-04,  7.48470120e-05,  5.48867392e-05],\n",
       "        ...,\n",
       "        [ 1.88578060e-03, -7.48887076e-04, -7.50314444e-04, ...,\n",
       "         -3.41606210e-03,  1.70127372e-03, -2.08117854e-04],\n",
       "        [ 1.87496468e-03, -7.69626233e-04, -7.69291422e-04, ...,\n",
       "         -3.47064785e-03,  1.71598664e-03, -2.24176343e-04],\n",
       "        [ 1.86449569e-03, -7.87395111e-04, -7.85175245e-04, ...,\n",
       "         -3.51756671e-03,  1.72959256e-03, -2.38487992e-04]],\n",
       "\n",
       "       [[ 1.25659644e-04,  1.05638996e-04,  1.64925543e-04, ...,\n",
       "         -9.08747534e-05,  1.95486442e-04,  9.62465419e-05],\n",
       "        [ 1.17789335e-04,  4.58500290e-05,  2.95297330e-04, ...,\n",
       "         -8.02840659e-05,  1.92511958e-04,  8.98813232e-05],\n",
       "        [ 3.37374251e-04,  1.00494690e-04,  3.05414171e-04, ...,\n",
       "         -5.94266530e-05,  1.49247731e-04,  1.50956446e-04],\n",
       "        ...,\n",
       "        [ 1.82691787e-03, -8.49606819e-04, -8.35376442e-04, ...,\n",
       "         -3.66804074e-03,  1.75950630e-03, -3.22564825e-04],\n",
       "        [ 1.82049349e-03, -8.54695274e-04, -8.38766340e-04, ...,\n",
       "         -3.68648046e-03,  1.77308335e-03, -3.24263703e-04],\n",
       "        [ 1.81489438e-03, -8.58611369e-04, -8.41625617e-04, ...,\n",
       "         -3.70194367e-03,  1.78479974e-03, -3.25861882e-04]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for src_sample, tgt_sample in train_dataset.take(1): \n",
    "    break\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "italic-anthropology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  1536128   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  1312768   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  2099200   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  6156513   \n",
      "=================================================================\n",
      "Total params: 11,104,609\n",
      "Trainable params: 11,104,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "drawn-cameroon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "549/549 [==============================] - 256s 467ms/step - loss: 1.2146 - val_loss: 5.2073\n",
      "Epoch 2/10\n",
      "549/549 [==============================] - 263s 480ms/step - loss: 0.9835 - val_loss: 4.7995\n",
      "Epoch 3/10\n",
      "549/549 [==============================] - 255s 465ms/step - loss: 0.9286 - val_loss: 4.0683\n",
      "Epoch 4/10\n",
      "549/549 [==============================] - 267s 487ms/step - loss: 0.9226 - val_loss: 1.6691\n",
      "Epoch 5/10\n",
      "549/549 [==============================] - 264s 480ms/step - loss: 0.8671 - val_loss: 1.5621\n",
      "Epoch 6/10\n",
      "549/549 [==============================] - 267s 487ms/step - loss: 0.8368 - val_loss: 1.5647\n",
      "Epoch 7/10\n",
      "549/549 [==============================] - 268s 488ms/step - loss: 0.8088 - val_loss: 1.5914\n",
      "Epoch 8/10\n",
      "549/549 [==============================] - 267s 487ms/step - loss: 0.7822 - val_loss: 1.6097\n",
      "Epoch 9/10\n",
      "549/549 [==============================] - 268s 488ms/step - loss: 0.7571 - val_loss: 1.6365\n",
      "Epoch 10/10\n",
      "549/549 [==============================] - 269s 491ms/step - loss: 0.7331 - val_loss: 1.6627\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()        \n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(             \n",
    "    from_logits=True,             \n",
    "    reduction='none'        \n",
    ")        \n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)     \n",
    "history = model.fit(train_dataset, epochs=10, validation_data=test_dataset)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "alternate-environment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(loss))\n",
    "\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-beaver",
   "metadata": {},
   "source": [
    "## 06. evlauate model\n",
    "- 문장을 생성해 모델의 성능을 평가합니다. \n",
    "- 작문 모델을 평가하기 위해서 생성된 문장을 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "oriented-depression",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 입력받은 init_sentence를 텐서로 변환합니다.\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 루프를 돌면서 init_sentence에 살을 붙여나갑니다.\n",
    "    while True:\n",
    "        predict = model(test_tensor)   \n",
    "        # 마지막 단어가 새롭게 예측한 단어입니다. \n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]   \n",
    "\n",
    "        # 새롭게 예측한 단어를 init_sentence의 뒤에 붙여 줍니다. \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "\n",
    "        # 모델이 <end>를 예측했거나, max_len에 도달하면  while 루프를 탈출해 모델 작동을 멈춥니다.\n",
    "        if predict_word.numpy()[0] == end_token: \n",
    "            break\n",
    "        if test_tensor.shape[1] >= max_len: \n",
    "            break\n",
    "\n",
    "    generated = \"\"\n",
    "    # word index를 tokenizer.index_word 사전을 통해 실제 단어로 하나씩 변환합니다. \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated   # 최종적으로 모델이 생성한 자연어 문장입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-finder",
   "metadata": {},
   "source": [
    "노래 가사로 많이 쓰일 법한 말들을 입력 문장으로 넣어줍니다.   \n",
    "제법 노래가사스러운 작문을 해낸 것을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "complex-chester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you , i m not gonna be <end> '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i love\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "higher-memorial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> baby , baby , baby , baby , baby , baby , baby , baby , baby , baby '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> baby\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "confused-effects",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> cause i want to be a little selfish <end> '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> cause i want\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "known-headset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i can see you in the club <end> '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i can see\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "hydraulic-millennium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> have yourself a merry bag , <end> '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> Have yourself a merry\", max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-louisiana",
   "metadata": {},
   "source": [
    "다만 영어에서 많이 쓰이는 '(apostrophe)에 대한 처리를 unknown word로 처리하기 때문에,   \n",
    "전처리 과정에서 이런 문제를 해결해야할 것으로 보입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "female-fifth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i <unk> want a lot of fame <end> '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> I don't want a lot\", max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-carbon",
   "metadata": {},
   "source": [
    "# 정리     \n",
    "---        \n",
    "1. 데이터 불러오기           \n",
    "    - 각 파일을 읽은 후, 파일의 문장단위를 저장해 말뭉치(courpus)를 만든다.      \n",
    "    - glob모듈을 이용해 파일을 쉽게 읽을 수 있다.   \n",
    "2. 데이터 전처리         \n",
    "    - 영문을 모두 소문자로 변환한다.                 \n",
    "    - 특수문자, 공백 패턴 등을 모두 제거한다.                     \n",
    "    - 단어에 공백을 주어 토큰화가 쉽게해준다.             \n",
    "3. 데이터 토큰화    \n",
    "    - 토크나이저 객체를 생성한다.\n",
    "    - 토크나이저를 통해 사전을 구축하고, 사전에서 tensor로 변환한다. \n",
    "4. 데이터 분할       \n",
    "    - \\<start>, \\<end> 토큰을 기준으로 슬라이싱해 소스 문장, 타겟 문장을 생성한다.\n",
    "    - train, test split을 진행한다.\n",
    "    - tf.data.Dataset을 통해 학습 데이터셋, 평가 데이터셋을 만든다. \n",
    "5. 작문 모델 생성          \n",
    "    - layer를 subclassing하는 방법으로 모델을 생성한다.\n",
    "    - 모델로 학습을 진행한다. \n",
    "6. 모델 성능 평가        \n",
    "    - 문장의 첫 단어를 입력 문장으로 넣어 학습한 모델로 예측을 한다.\n",
    "    - 예측된 tensor를 단어로 변환하여, 모델로 생성된 문장을 직접 평가한다. \n",
    "\n",
    "\n",
    "# 루브릭 평가\n",
    "---\n",
    "1. **가사 텍스트 생성 모델이 정상적으로 동작하는가?**   \n",
    "    - 실제 영어 노래 가사의 첫 단어를 넣었을 때, 말이 되는 그럴듯한 문장으로 생성되는 것을 볼 수 있었습니다.  \n",
    "     \n",
    "     \n",
    "2. **데이터의 전처리와 데이터셋 구성 과정이 체계적으로 진행되었는가?**  \n",
    "    - 구성 과정은 **#정리**를 참고하면 진행사항을 참고할 수 있습니다.    \n",
    "     \n",
    "     \n",
    "3. **텍스트 생성모델이 안정적으로 학습되었는가?**  \n",
    "    - embedding size=256, hidden size=1024로 설정해 epoch 10회를 진행한 결과, validation loss 1.6627 를 달성했습니다.  \n",
    "\n",
    "    \n",
    "# 회고\n",
    "---\n",
    "## 더 공부하고 싶은 부분\n",
    "- 아직 **토큰화**에 대해 정확하게 이해를 하지 못한 것 같아 이 부분에 대한 공부가 필요합니다. \n",
    "\n",
    "## 느낀 점\n",
    "해당 모델은 영어로 진행되었기 때문에 언어에 맞는 전처리 과정이 필요하다는 것을 느꼈습니다. 또한 의미있는 문장을 얻기 위해서 문장의 최대 길이를 설정하는 부분이 중요했습니다. 프로젝트 설명에는 15를 권장하였으나, 최대 길이를 15로 했을 때는 너무 짧은 문장이 예측되었기 때문에 50으로 설정해 진행했습니다. 가사라는 것이 곡의 장르에 따라 가사의 종류도 나뉜다고 생각합니다. *예를 들어, 한국의 k-pop의 경우, 의미없는 가사의 반복이 많습니다.* 곡의 종류와 가사를 함께 학습시키면 이런 부분을 해소할 수 있을 것이라고 여겨집니다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
